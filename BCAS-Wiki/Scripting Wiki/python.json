{
  "guide": {
    "tools": [
      {
        "name": "File Operations (Basic)",
        "category": "I/O Operations",
        "description": "Reading, writing, and manipulating files in Python using built-in functions.",
        "usage": "with open('filename', 'mode') as file:",
        "examples": [
          "# Reading a whole file into a string",
          "with open('data.txt', 'r') as f:",
          "    content = f.read()",
          "print(content)",
          "",
          "# Reading a file line by line",
          "with open('lines.txt', 'r') as f:",
          "    for line in f:",
          "        print(line.strip()) # .strip() removes leading/trailing whitespace, including newline",
          "",
          "# Writing a new file",
          "with open('output.txt', 'w') as f:",
          "    f.write('Hello Python World!\\n')",
          "    f.write('This is a new line.')",
          "",
          "# Appending to an existing file",
          "with open('output.txt', 'a') as f:",
          "    f.write('\\nAppended content.')",
          "",
          "# Reading binary files (e.g., images)",
          "with open('image.jpg', 'rb') as f:",
          "    binary_data = f.read()",
          "",
          "# Writing binary files",
          "with open('copy_image.jpg', 'wb') as f:",
          "    f.write(binary_data)"
        ],
        "notes": "Always use `with open(...)` (context manager) for file operations. It ensures files are properly closed, even if errors occur. Common modes: 'r' (read), 'w' (write, overwrites existing), 'a' (append), 'x' (create new, error if exists), 'b' (binary mode), 't' (text mode, default). Combine with 'b' for binary files (e.g., 'rb', 'wb')."
      },
      {
        "name": "Regular Expressions",
        "category": "Text Processing",
        "description": "Pattern matching and text manipulation using the `re` module for regular expressions.",
        "usage": "import re; re.search(pattern, text)",
        "examples": [
          "import re",
          "",
          "# Find all numbers in a string",
          "text = 'Price: 25 dollars, Quantity: 100 units'",
          "numbers = re.findall(r'\\d+', text)",
          "print(f'Numbers found: {numbers}')",
          "",
          "# Replace all whitespace with underscores",
          "cleaned_text = re.sub(r'\\s+', '_', 'hello   world   test')",
          "print(f'Cleaned text: {cleaned_text}')",
          "",
          "# Check if a string contains only letters (case-insensitive)",
          "if re.match(r'^[a-zA-Z]+$', 'onlyletters'):",
          "    print('String contains only letters')",
          "else:",
          "    print('String contains non-letter characters')",
          "",
          "# Extract specific parts using groups",
          "log_line = 'ERROR: [2023-10-26 14:30:05] File not found: data.txt'",
          "if match:",
          "    timestamp = match.group(1)",
          "    message = match.group(2)",
          "    print(f'Timestamp: {timestamp}, Message: {message}')",
          "",
          "# Compile a regex for better performance if used multiple times",
          "email_pattern = re.compile(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$')",
          "if email_pattern.match('test@example.com'):",
          "    print('Valid email address')",
          "",
          "# More advanced regex: lookarounds",
          "text_with_currency = 'I have $100 and €50 and £20.'",
          "amounts = re.findall(r'(?<=[$€£])\\d+', text_with_currency) # Positive lookbehind",
          "print(f'Amounts: {amounts}') # ['100', '50', '20']",
          "",
          "# Non-capturing groups and quantifiers",
          "phone_numbers = 'Call 123-456-7890 or 987.654.3210'",
          "found_phones = re.findall(r'\\b\\d{3}[-. ]?\\d{3}[-. ]?\\d{4}\\b', phone_numbers)",
          "print(f'Found phones: {found_phones}')"
        ],
        "notes": "Use raw strings (`r'pattern'`) for regex patterns to avoid issues with backslash escaping. `re.findall()` returns all non-overlapping matches. `re.sub()` replaces matches. `re.match()` checks for a match at the beginning of the string. `re.search()` finds the first match anywhere in the string. `re.compile()` pre-compiles a regex for efficiency when used repeatedly. Capturing groups `()` extract specific parts of the matched text. Lookarounds (`(?<=...)`, `(?=...)`) assert position without consuming characters. Quantifiers (`+`, `*`, `?`, `{n,m}`) control repetition."
      },
      {
        "name": "JSON Handling",
        "category": "Data Processing",
        "description": "Parsing and generating JSON (JavaScript Object Notation) data using the `json` module.",
        "usage": "import json; json.loads(json_string)",
        "examples": [
          "import json",
          "",
          "# Load JSON from a string",
          "json_string = '{\"name\": \"John Doe\", \"age\": 30, \"isStudent\": false, \"courses\": [\"Math\", \"Science\"]}'",
          "data = json.loads(json_string)",
          "print(f'Name: {data[\"name\"]}, Age: {data[\"age\"]}')",
          "",
          "# Dump Python dictionary to a JSON string",
          "python_dict = {'product': 'Laptop', 'price': 1200.50, 'available': True}",
          "json_output = json.dumps(python_dict, indent=4)",
          "print(f'\\nJSON Output:\\n{json_output}')",
          "",
          "# Load JSON from a file",
          "with open('config.json', 'w') as f:",
          "    json.dump({'setting1': 'value1', 'setting2': 123}, f, indent=4)",
          "print('\\nCreated config.json')",
          "",
          "with open('config.json', 'r') as f:",
          "    config_data = json.load(f)",
          "print(f'Loaded from file: {config_data}')",
          "",
          "# Handling JSON with custom objects (requires __dict__ or custom encoder)",
          "class User:",
          "    def __init__(self, name, email):",
          "        self.name = name",
          "        self.email = email",
          "",
          "    def to_json(self):",
          "        return {'name': self.name, 'email': self.email}",
          "",
          "user_obj = User('Alice', 'alice@example.com')",
          "user_json = json.dumps(user_obj.to_json(), indent=2)",
          "print(f'\\nCustom object to JSON:\\n{user_json}')",
          "",
          "# Custom JSON Decoder (for complex types, e.g. datetime objects)",
          "from datetime import datetime",
          "class CustomEncoder(json.JSONEncoder):",
          "    def default(self, obj):",
          "        if isinstance(obj, datetime):",
          "            return obj.isoformat()",
          "        return json.JSONEncoder.default(self, obj)",
          "",
          "dt = datetime.now()",
          "print(f'\\nDatetime serialized with custom encoder: {json.dumps(dt, cls=CustomEncoder)}')",
          "",
          "import os",
          "if os.path.exists('config.json'): os.remove('config.json')"
        ],
        "notes": "`json.load()` reads a JSON object from a file-like object. `json.loads()` reads a JSON object from a string. `json.dump()` writes a Python object to a file-like object as JSON. `json.dumps()` writes a Python object to a string as JSON. Use `indent` argument in `dump`/`dumps` for pretty-printing. JSON numbers are floats, Python integers are converted correctly. For custom Python objects, you often need to provide a method (like `to_json`) or a custom `JSONEncoder` subclass to define how to serialize them."
      },
      {
        "name": "HTTP Requests (requests library)",
        "category": "Network",
        "description": "Making HTTP requests (GET, POST, etc.) to web services using the `requests` library.",
        "usage": "import requests; requests.get(url)",
        "examples": [
          "import requests",
          "",
          "# Simple GET request",
          "try:",
          "    response = requests.get('https://api.github.com/users/octocat')",
          "    response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)",
          "    user_data = response.json()",
          "    print(f'GitHub user: {user_data.get(\"login\")}, Public Repos: {user_data.get(\"public_repos\")}')",
          "except requests.exceptions.RequestException as e:",
          "    print(f'Error fetching data: {e}')",
          "",
          "# POST request with JSON data",
          "try:",
          "    payload = {'name': 'New Item', 'price': 25.99}",
          "    headers = {'Content-Type': 'application/json'}",
          "    post_response = requests.post('https://httpbin.org/post', json=payload, headers=headers)",
          "    post_response.raise_for_status()",
          "    print(f'\\nPOST response status: {post_response.status_code}')",
          "    print(f'POST response JSON: {post_response.json().get(\"json\")}')",
          "except requests.exceptions.RequestException as e:",
          "    print(f'Error sending POST request: {e}')",
          "",
          "# GET request with query parameters and custom headers",
          "try:",
          "    params = {'q': 'Python programming', 'limit': 3}",
          "    headers = {'User-Agent': 'MyPythonApp/1.0', 'Accept': 'application/json'}",
          "    search_response = requests.get('https://jsonplaceholder.typicode.com/posts', params=params, headers=headers)",
          "    search_response.raise_for_status()",
          "    print(f'\\nSearch results (first post title): {search_response.json()[0].get(\"title\")}')",
          "except requests.exceptions.RequestException as e:",
          "    print(f'Error searching: {e}')",
          "",
          "# Session management for persistent connections/cookies",
          "with requests.Session() as session:",
          "    session.get('https://httpbin.org/cookies/set/sessioncookie/123')",
          "    r = session.get('https://httpbin.org/cookies')",
          "    print(f'\\nSession cookies: {r.json().get(\"cookies\")}')"
        ],
        "notes": "The `requests` library is not built-in and needs to be installed (`pip install requests`). Always include error handling for network operations using `try-except` blocks. `response.raise_for_status()` is a convenient way to check for HTTP error codes. Use `response.json()` to parse JSON responses and `json=payload` for POST requests with JSON body. `params` sends query parameters, `headers` sets HTTP headers. `requests.Session()` allows for persistent connections and cookie management, improving performance and simplifying interactions with stateful APIs."
      },
      {
        "name": "Command Line Arguments (argparse)",
        "category": "System",
        "description": "Parsing command line arguments for more complex scripts using the `argparse` module.",
        "usage": "import argparse; parser = argparse.ArgumentParser()",
        "examples": [
          "import argparse",
          "",
          "# Define the parser and arguments",
          "parser = argparse.ArgumentParser(description='A simple script with command-line arguments.')",
          "parser.add_argument('--input', help='Path to the input file.')",
          "parser.add_argument('-o', '--output', default='output.txt', help='Path to the output file (default: output.txt).')",
          "parser.add_argument('-v', '--verbose', action='store_true', help='Enable verbose output.')",
          "parser.add_argument('--count', type=int, default=1, help='Number of times to run (default: 1).')",
          "parser.add_argument('positional_arg', nargs='?', help='An optional positional argument.')",
          "",
          "# Add mutually exclusive group (e.g., --local or --remote)",
          "group = parser.add_mutually_exclusive_group()",
          "group.add_argument('--local', action='store_true', help='Use local mode.')",
          "group.add_argument('--remote', action='store_true', help='Use remote mode.')",
          "",
          "# Parse the arguments (usually from sys.argv)",
          "args = parser.parse_args()",
          "",
          "# Access arguments",
          "print(f'Input file: {args.input}')",
          "print(f'Output file: {args.output}')",
          "if args.verbose:",
          "    print('Verbose mode enabled.')",
          "print(f'Count: {args.count}')",
          "print(f'Positional arg: {args.positional_arg}')",
          "if args.local: print('Mode: Local')",
          "if args.remote: print('Mode: Remote')",
          "",
          "# Example usage from command line (assuming script is named 'my_script.py'):",
          "# python my_script.py --input data.csv -v --count 5 -o results.log positional_value",
          "# python my_script.py --local",
          "# python my_script.py --local --remote # This would raise an error due to mutual exclusion"
        ],
        "notes": "`argparse` is the recommended module for robust command-line argument parsing, especially for scripts with multiple options. `add_argument()` defines arguments with their names, help text, default values, and types (`type=int`, `action='store_true'` for flags). `parser.parse_args()` processes the arguments. For very simple cases, `sys.argv` (a list of strings) can be used, but lacks built-in help and type conversion. `nargs` can specify how many arguments an option expects (`'?'` for 0 or 1, `'*'` for 0 or more, `'+'` for 1 or more). `add_mutually_exclusive_group()` ensures that only one argument from the group can be present."
      },
      {
        "name": "Directory Operations (os module)",
        "category": "File System",
        "description": "Navigating and manipulating directories using the `os` module.",
        "usage": "import os; os.chdir(path)",
        "examples": [
          "import os",
          "",
          "# Get current working directory",
          "current_dir = os.getcwd()",
          "print(f'Current directory: {current_dir}')",
          "",
          "# Create a new directory",
          "new_dir = 'my_new_folder'",
          "os.makedirs(new_dir, exist_ok=True) # exist_ok=True prevents error if dir exists",
          "print(f'Created directory: {os.path.abspath(new_dir)}')",
          "",
          "# Change current directory",
          "os.chdir(new_dir)",
          "print(f'Changed to: {os.getcwd()}')",
          "",
          "# Go back to the parent directory",
          "os.chdir('..')",
          "print(f'Changed back to: {os.getcwd()}')",
          "",
          "# List contents of a directory",
          "print('\\nContents of current directory:')",
          "for item in os.listdir('.'):",
          "    print(item)",
          "",
          "# Walk through directory tree (for recursive operations)",
          "print('\\nWalking through directory tree:')",
          "for root, dirs, files in os.walk('.'):",
          "    print(f'Root: {root}')",
          "    print(f'  Directories: {dirs}')",
          "    print(f'  Files: {files}')",
          "",
          "# Remove an empty directory",
          "empty_dir = 'temp_empty_dir'",
          "os.makedirs(empty_dir, exist_ok=True)",
          "os.rmdir(empty_dir)",
          "print(f'Removed empty directory: {empty_dir}')",
          "",
          "# Remove a non-empty directory (DANGER: deletes contents recursively!)",
          "import shutil",
          "non_empty_dir = 'temp_non_empty_dir'",
          "os.makedirs(os.path.join(non_empty_dir, 'subdir'), exist_ok=True)",
          "with open(os.path.join(non_empty_dir, 'test.txt'), 'w') as f: f.write('hi')",
          "# shutil.rmtree(non_empty_dir) # Uncomment to remove a non-empty directory"
        ],
        "notes": "`os.getcwd()` gets the current working directory. `os.chdir(path)` changes it. `os.mkdir(path)` creates a single directory, `os.makedirs(path, exist_ok=True)` creates nested directories and doesn't error if they exist. `os.rmdir(path)` removes an empty directory. For non-empty directories, use `shutil.rmtree(path)` (use with extreme caution!). `os.listdir()` lists contents. `os.walk()` is excellent for recursively traversing a directory tree."
      },
      {
        "name": "Environment Variables",
        "category": "System",
        "description": "Accessing and modifying system environment variables using the `os` module.",
        "usage": "import os; os.environ.get('VAR_NAME')",
        "examples": [
          "import os",
          "",
          "# Get an environment variable, with a default if not found",
          "home_dir = os.environ.get('HOME') or os.environ.get('USERPROFILE')",
          "print(f'Home directory: {home_dir}')",
          "",
          "temp_dir = os.environ.get('TEMP', '/tmp/default')",
          "print(f'Temp directory (with default): {temp_dir}')",
          "",
          "# Set an environment variable (for current process and its children)",
          "os.environ['MY_CUSTOM_VAR'] = 'my_value_123'",
          "print(f'MY_CUSTOM_VAR: {os.environ.get(\"MY_CUSTOM_VAR\")}')",
          "",
          "# Iterate through all environment variables",
          "print('\\nAll environment variables (first 5):')",
          "for key, value in list(os.environ.items())[:5]:",
          "    print(f'  {key}={value}')",
          "",
          "# Modify PATH variable (for current process)",
          "current_path = os.environ.get('PATH', '')",
          "new_bin_path = 'C:\\MyNewTools\\bin'",
          "if new_bin_path not in current_path:",
          "    os.environ['PATH'] = f'{current_path}{os.pathsep}{new_bin_path}'",
          "    print(f'PATH updated (for this session): {os.environ[\"PATH\"]}')"
        ],
        "notes": "`os.environ` is a dictionary-like object representing environment variables. Use `os.environ.get('VAR_NAME', default_value)` to safely retrieve a variable and provide a default if it's not set, avoiding `KeyError`. Setting a variable (e.g., `os.environ['MY_VAR'] = 'value'`) only affects the current Python process and any child processes it spawns. It does *not* permanently modify system-wide environment variables."
      },
      {
        "name": "Process Management (subprocess)",
        "category": "System",
        "description": "Executing external commands and managing system processes using the `subprocess` module.",
        "usage": "import subprocess; subprocess.run(['command', 'arg1'])",
        "examples": [
          "import subprocess",
          "import sys",
          "",
          "# Run a simple command and capture output",
          "try:",
          "    result = subprocess.run(['echo', 'Hello from subprocess!'], capture_output=True, text=True, check=True)",
          "    print(f'Output: {result.stdout.strip()}')",
          "    print(f'Exit Code: {result.returncode}')",
          "except subprocess.CalledProcessError as e:",
          "    print(f'Command failed with exit code {e.returncode}: {e.stderr}')",
          "",
          "# Run a command in the background (Popen)",
          "print('\\nStarting Notepad in the background...')",
          "try:",
          "    # `shell=True` can be a security risk if command comes from untrusted input",
          "    # Use it carefully or with known commands only.",
          "    process = subprocess.Popen(['notepad.exe'], shell=True)",
          "    print(f'Notepad PID: {process.pid}')",
          "    # process.wait() # Uncomment to wait for Notepad to close",
          "    # print('Notepad closed.')",
          "except FileNotFoundError:",
          "    print('Notepad.exe not found. Skipping.')",
          "",
          "# Run a command and pipe output to another command",
          "print('\\nListing files and finding .py files:')",
          "try:",
          "    # Equivalent to: ls -la | grep .py (on Linux/macOS)",
          "    # On Windows: dir | findstr .py",
          "    list_files = subprocess.Popen(['dir'], stdout=subprocess.PIPE, shell=True)",
          "    filter_py = subprocess.run(['findstr', '.py'], stdin=list_files.stdout, capture_output=True, text=True, check=True, shell=True)",
          "    list_files.stdout.close() # Allow list_files to receive a SIGPIPE if findstr exits",
          "    print(filter_py.stdout)",
          "except subprocess.CalledProcessError as e:",
          "    print(f'Piping command failed: {e.stderr}')",
          "",
          "# Calling a Python script with arguments",
          "print('\\nCalling another Python script:')",
          "try:",
          "    # Create a dummy script for demonstration",
          "    with open('dummy_script.py', 'w') as f:",
          "        f.write('import sys\\nprint(f\"Hello from {sys.argv[1]} and {sys.argv[2]}\")')",
          "    subprocess.run([sys.executable, 'dummy_script.py', 'Alice', 'Bob'], check=True)",
          "except FileNotFoundError:",
          "    print(\"Error: 'dummy_script.py' not found.\")",
          "finally:",
          "    # Clean up dummy script",
          "    if os.path.exists('dummy_script.py'): os.remove('dummy_script.py')"
        ],
        "notes": "`subprocess.run()` is for running commands and waiting for them to complete. `capture_output=True` captures stdout/stderr. `text=True` decodes output as text. `check=True` raises `CalledProcessError` if the command returns a non-zero exit code. `subprocess.Popen()` runs a command in a non-blocking way, allowing more control (e.g., interacting with stdin/stdout, sending signals). Be cautious with `shell=True` as it can introduce security vulnerabilities if command strings contain untrusted input. Prefer passing commands as a list of arguments."
      },
      {
        "name": "Date and Time",
        "category": "Utilities",
        "description": "Handling dates, times, and timestamps using `datetime` and `time` modules.",
        "usage": "from datetime import datetime",
        "examples": [
          "from datetime import datetime, timedelta, timezone",
          "import time",
          "",
          "# Get current date and time",
          "now = datetime.now()",
          "print(f'Current date and time: {now}')",
          "",
          "# Get current date only",
          "today = datetime.today().date()",
          "print(f'Current date: {today}')",
          "",
          "# Format a datetime object into a string",
          "formatted_date = now.strftime('%Y-%m-%d %H:%M:%S')",
          "print(f'Formatted: {formatted_date}')",
          "",
          "# Parse a string into a datetime object",
          "date_string = '2023-01-01 10:30:00'",
          "parsed_date = datetime.strptime(date_string, '%Y-%m-%d %H:%M:%S')",
          "print(f'Parsed: {parsed_date}')",
          "",
          "# Perform date arithmetic (e.g., add days)",
          "future_date = now + timedelta(days=7, hours=2)",
          "print(f'One week and two hours from now: {future_date}')",
          "",
          "# Calculate difference between two datetimes",
          "time_diff = future_date - now",
          "print(f'Time difference: {time_diff}')",
          "print(f'Total seconds in diff: {time_diff.total_seconds()}')",
          "",
          "# Get a timestamp (seconds since epoch)",
          "timestamp = time.time()",
          "print(f'Current Unix timestamp: {timestamp}')",
          "",
          "# Pause script execution",
          "print('Pausing for 2 seconds...')",
          "time.sleep(2)",
          "print('Resumed.')",
          "",
          "# Working with Timezones (Python 3.2+ for timezone objects, or use pytz)",
          "utc_now = datetime.now(timezone.utc)",
          "print(f'UTC Now: {utc_now}')",
          "local_timezone_offset = datetime.now().astimezone().tzinfo",
          "print(f'Local timezone offset: {local_timezone_offset}')",
          "",
          "# Example with a fixed offset timezone",
          "from datetime import timedelta, timezone",
          "CST = timezone(timedelta(hours=-6))",
          "cst_time = datetime.now(CST)",
          "print(f'Current CST time: {cst_time}')",
          "",
          "# Using date.weekday() and date.isoweekday()",
          "today_date = datetime.now().date()",
          "print(f'Today is weekday number (0=Mon, 6=Sun): {today_date.weekday()}')",
          "print(f'Today is ISO weekday number (1=Mon, 7=Sun): {today_date.isoweekday()}')"
        ],
        "notes": "`datetime` module provides `datetime` objects for date/time, `date` objects for dates, and `time` objects for times. `timedelta` is used for date arithmetic. `strftime()` formats a datetime object into a string, `strptime()` parses a string into a datetime object. The `time` module offers `time.time()` for Unix timestamps and `time.sleep()` for pausing execution. For robust timezone handling, especially with historical data or daylight saving, consider the `pytz` library (`pip install pytz`) which provides time zone definitions from the IANA Time Zone Database. Python 3.2+ introduced `datetime.timezone` for fixed offsets."
      },
      {
        "name": "Database Operations (sqlite3)",
        "category": "Database",
        "description": "Connecting to and querying SQLite databases, which is built into Python.",
        "usage": "import sqlite3; conn = sqlite3.connect('db.sqlite')",
        "examples": [
          "import sqlite3",
          "",
          "# Connect to an in-memory database (temporary)",
          "conn = sqlite3.connect(':memory:')",
          "cursor = conn.cursor()",
          "",
          "# Create a table",
          "cursor.execute('''",
          "    CREATE TABLE users (",
          "        id INTEGER PRIMARY KEY,",
          "        name TEXT NOT NULL,",
          "        email TEXT UNIQUE NOT NULL",
          "    )",
          "''')",
          "conn.commit()",
          "print('Table created successfully.')",
          "",
          "# Insert data (parameterized query to prevent SQL injection)",
          "user_data = [('Alice', 'alice@example.com'), ('Bob', 'bob@example.com')]",
          "cursor.executemany('INSERT INTO users (name, email) VALUES (?, ?)', user_data)",
          "conn.commit()",
          "print('Data inserted successfully.')",
          "",
          "# Query data",
          "cursor.execute('SELECT * FROM users WHERE name = ?', ('Alice',))",
          "row = cursor.fetchone()",
          "print(f'Found user: {row}')",
          "",
          "# Query all data",
          "cursor.execute('SELECT name, email FROM users')",
          "all_users = cursor.fetchall()",
          "print('\\nAll users:')",
          "for user in all_users:",
          "    print(f'  Name: {user[0]}, Email: {user[1]}')",
          "",
          "# Update data",
          "cursor.execute('UPDATE users SET email = ? WHERE name = ?', ('alice.new@example.com', 'Alice'))",
          "conn.commit()",
          "print('\\nUser updated.')",
          "",
          "# Delete data",
          "cursor.execute('DELETE FROM users WHERE name = ?', ('Bob',))",
          "conn.commit()",
          "print('User deleted.')",
          "",
          "# Using row_factory for dictionary-like access",
          "conn.row_factory = sqlite3.Row",
          "cursor = conn.cursor()",
          "cursor.execute('SELECT * FROM users WHERE name = ?', ('Alice',))",
          "row_dict = cursor.fetchone()",
          "if row_dict: print(f'User by name: {row_dict[\"name\"]}, email: {row_dict[\"email\"]}')",
          "",
          "conn.close() # Close the connection"
        ],
        "notes": "`sqlite3` is a lightweight, file-based database built into Python. `sqlite3.connect()` establishes a connection. Use `conn.cursor()` to create a cursor object for executing SQL commands. `cursor.execute()` runs a single SQL command. `cursor.executemany()` runs a command for multiple sets of data. Always use question mark placeholders (`?`) for parameters in SQL queries and pass values as a tuple/list to `execute()` or `executemany()` to prevent SQL injection. `conn.commit()` saves changes, `conn.rollback()` undoes them. `cursor.fetchone()` retrieves one row, `cursor.fetchall()` retrieves all remaining rows. Setting `conn.row_factory = sqlite3.Row` allows accessing columns by name like a dictionary, which improves readability."
      },
      {
        "name": "CSV Processing",
        "category": "Data Processing",
        "description": "Reading from and writing to CSV (Comma Separated Values) files using the `csv` module.",
        "usage": "import csv; csv.reader(file)",
        "examples": [
          "import csv",
          "import os",
          "",
          "# Sample data",
          "data = [",
          "    {'Name': 'Alice', 'Age': 30, 'City': 'New York'},",
          "    {'Name': 'Bob', 'Age': 24, 'City': 'London'},",
          "    {'Name': 'Charlie', 'Age': 35, 'City': 'Paris'}",
          "]",
          "headers = ['Name', 'Age', 'City']",
          "",
          "# Write data to a CSV file (using DictWriter)",
          "output_csv_file = 'output.csv'",
          "with open(output_csv_file, 'w', newline='') as csvfile:",
          "    writer = csv.DictWriter(csvfile, fieldnames=headers)",
          "    writer.writeheader() # Write the header row",
          "    writer.writerows(data)",
          "print(f'Data written to {output_csv_file}')",
          "",
          "# Read data from a CSV file (using DictReader)",
          "with open(output_csv_file, 'r', newline='') as csvfile:",
          "    reader = csv.DictReader(csvfile)",
          "    print('\\nReading data:')",
          "    for row in reader:",
          "        print(f'  {row[\"Name\"]} is {row[\"Age\"]} years old and lives in {row[\"City\"]}.')",
          "",
          "# Read data from a CSV file (using regular reader for row-based access)",
          "with open(output_csv_file, 'r', newline='') as csvfile:",
          "    reader = csv.reader(csvfile)",
          "    header_row = next(reader) # Read the header row",
          "    print(f'\\nHeaders: {header_row}')",
          "    print('Reading data (row-based):')",
          "    for row in reader:",
          "        print(f'  Row: {row}')",
          "",
          "# Handling custom delimiters and quotes",
          "custom_csv_data = ['id;name;value', '1;Item A;100', '2;\"Item B, with comma\";200']",
          "custom_csv_file = 'custom_delim.csv'",
          "with open(custom_csv_file, 'w', newline='') as f:",
          "    for line in custom_csv_data: f.write(line + '\\n')",
          "",
          "with open(custom_csv_file, 'r', newline='') as csvfile:",
          "    reader = csv.reader(csvfile, delimiter=';', quotechar='\"')",
          "    for row in reader:",
          "        print(f'Custom CSV Row: {row}')",
          "",
          "# Clean up the created files",
          "if os.path.exists(output_csv_file):",
          "    os.remove(output_csv_file)",
          "if os.path.exists(custom_csv_file):",
          "    os.remove(custom_csv_file)"
        ],
        "notes": "`csv.reader()` and `csv.writer()` work with lists of strings (rows). `csv.DictReader()` and `csv.DictWriter()` are generally preferred as they work with dictionaries, using the header row as keys, making data access more readable. Always use `newline=''` when opening CSV files to prevent extra blank rows, as `csv` module handles universal newlines. `writer.writeheader()` should be called before `writerows()` with `DictWriter`. The `delimiter` and `quotechar` arguments are crucial for handling non-standard CSV formats."
      },
      {
        "name": "Logging",
        "category": "Debugging",
        "description": "Implementing robust logging in applications for debugging, monitoring, and auditing using the `logging` module.",
        "usage": "import logging; logging.basicConfig(level=logging.INFO)",
        "examples": [
          "import logging",
          "import os",
          "",
          "# Basic configuration (logs to console by default)",
          "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')",
          "logging.debug('This is a debug message')",
          "logging.info('This is an info message')",
          "logging.warning('This is a warning message')",
          "logging.error('This is an error message')",
          "logging.critical('This is a critical message')",
          "",
          "# Logging to a file",
          "log_file = 'app.log'",
          "file_handler = logging.FileHandler(log_file)",
          "file_handler.setLevel(logging.INFO)",
          "file_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')",
          "file_handler.setFormatter(file_formatter)",
          "",
          "logger = logging.getLogger(__name__)",
          "logger.setLevel(logging.DEBUG) # Logger can handle all levels",
          "logger.addHandler(file_handler) # Add the file handler",
          "",
          "logger.info('Application started (logged to file).')",
          "try:",
          "    result = 10 / 0",
          "except ZeroDivisionError as e:",
          "    logger.exception('Division by zero error occurred! (logged to file)') # Logs exception traceback",
          "",
          "# Logging to Rotating File Handler",
          "from logging.handlers import RotatingFileHandler",
          "rotating_log_file = 'rotating_app.log'",
          "max_bytes = 1024 * 10 # 10 KB",
          "backup_count = 3",
          "rotating_handler = RotatingFileHandler(rotating_log_file, maxBytes=max_bytes, backupCount=backup_count)",
          "rotating_handler.setLevel(logging.INFO)",
          "rotating_handler.setFormatter(file_formatter)",
          "rotating_logger = logging.getLogger('rotating_logger')",
          "rotating_logger.setLevel(logging.INFO)",
          "rotating_logger.addHandler(rotating_handler)",
          "",
          "for i in range(100): # Write enough to trigger rotation",
          "    rotating_logger.info(f'Rotating log entry number {i}')",
          "print(f'\\nCheck {rotating_log_file} and its backups for rotating logs.')",
          "",
          "print(f'\\nCheck {log_file} for detailed logs.')",
          "",
          "# Clean up log file",
          "if os.path.exists(log_file): os.remove(log_file)",
          "for i in range(backup_count + 1):",
          "    if os.path.exists(f'{rotating_log_file}.{i}'): os.remove(f'{rotating_log_file}.{i}')",
          "if os.path.exists(rotating_log_file): os.remove(rotating_log_file)"
        ],
        "notes": "The `logging` module provides a flexible framework. Log levels (DEBUG, INFO, WARNING, ERROR, CRITICAL) indicate severity. `basicConfig()` sets up a simple handler for the root logger. For more control (multiple loggers, file logging, different formats), create `Logger` instances, `Handlers` (e.g., `StreamHandler` for console, `FileHandler` for files), and `Formatters`. `logger.exception()` is a convenient way to log an error with its full traceback. `RotatingFileHandler` is useful for managing log file sizes, automatically creating new log files when the current one reaches a certain size or number of lines. Proper logging helps immensely with debugging and monitoring deployed applications."
      },
      {
        "name": "Error Handling (Exceptions)",
        "category": "Exception Management",
        "description": "Handling exceptions and errors gracefully using `try`, `except`, `else`, and `finally` blocks.",
        "usage": "try: ... except Exception as e: ...",
        "examples": [
          "# Basic try-except block for specific error",
          "try:",
          "    result = 10 / 0",
          "except ZeroDivisionError:",
          "    print('Error: Cannot divide by zero!')",
          "",
          "# Catching multiple specific exceptions",
          "try:",
          "    num = int('abc')",
          "except ValueError:",
          "    print('Error: Invalid number format.')",
          "except TypeError:",
          "    print('Error: Type mismatch.')",
          "",
          "# Catching a generic exception (less specific, use with caution)",
          "try:",
          "    value = my_list[10] # Assume my_list is not defined or too short",
          "except Exception as e:",
          "    print(f'An unexpected error occurred: {e}')",
          "",
          "# try-except-else-finally structure",
          "file_name = 'non_existent.txt'",
          "try:",
          "    with open(file_name, 'r') as f:",
          "        content = f.read()",
          "    print(f'File content: {content}')",
          "except FileNotFoundError:",
          "    print(f'Error: File \\'{file_name}\\' not found.')",
          "except IOError as e:",
          "    print(f'Error reading file: {e}')",
          "else:",
          "    print('File read successfully (no exceptions in try block).')",
          "finally:",
          "    print('Cleanup or final actions always execute.')",
          "",
          "# Raising custom exceptions",
          "def validate_age(age):",
          "    if not isinstance(age, int):",
          "        raise TypeError('Age must be an integer.')",
          "    if age < 0:",
          "        raise ValueError('Age cannot be negative.')",
          "    print(f'Age {age} is valid.')",
          "",
          "try:",
          "    validate_age(-5)",
          "except (TypeError, ValueError) as e:",
          "    print(f'Validation error: {e}')",
          "",
          "# Using 'raise from' for exception chaining (Python 3)",
          "def process_data(data_source):",
          "    try:",
          "        # Simulate an error during data loading",
          "        if data_source == 'corrupt.json':",
          "            raise ValueError('Corrupt data encountered')",
          "        # ... process data ...",
          "    except ValueError as e:",
          "        raise RuntimeError('Failed to process data from source') from e",
          "",
          "try:",
          "    process_data('corrupt.json')",
          "except RuntimeError as e:",
          "    print(f'Top-level error: {e}')",
          "    if e.__cause__:",
          "        print(f'Caused by: {e.__cause__}')"
        ],
        "notes": "Use `try` to wrap code that might raise an exception. `except` blocks catch specific exceptions. It's best practice to catch specific exceptions rather than a generic `Exception` to avoid masking unexpected issues. The `else` block executes only if no exception occurred in the `try` block. The `finally` block *always* executes, regardless of whether an exception occurred or not, making it ideal for cleanup. Use `raise` to intentionally trigger an exception, often for input validation or error propagation. `raise ... from ...` allows explicit exception chaining, preserving the original cause of an error."
      },
      {
        "name": "List Comprehensions",
        "category": "Data Structures",
        "description": "Concise and efficient way to create lists based on existing iterables.",
        "usage": "[expression for item in iterable if condition]",
        "examples": [
          "# Basic list comprehension: squares of numbers",
          "squares = [x**2 for x in range(10)]",
          "print(f'Squares: {squares}') # [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]",
          "",
          "# List comprehension with a condition (filter even numbers)",
          "evens = [x for x in range(20) if x % 2 == 0]",
          "print(f'Evens: {evens}') # [0, 2, 4, ..., 18]",
          "",
          "# Transform elements (convert words to uppercase)",
          "words = ['hello', 'world', 'python', 'code']",
          "upper_words = [word.upper() for word in words]",
          "print(f'Uppercase words: {upper_words}') # ['HELLO', 'WORLD', 'PYTHON', 'CODE']",
          "",
          "# Nested list comprehension (flatten a list of lists)",
          "matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]",
          "flat_list = [num for row in matrix for num in row]",
          "print(f'Flattened list: {flat_list}') # [1, 2, 3, 4, 5, 6, 7, 8, 9]",
          "",
          "# List comprehension with if-else (conditional expression)",
          "numbers = [1, 2, 3, 4, 5, 6]",
          "odd_even = ['Even' if x % 2 == 0 else 'Odd' for x in numbers]",
          "print(f'Odd/Even: {odd_even}') # ['Odd', 'Even', 'Odd', 'Even', 'Odd', 'Even']",
          "",
          "# List comprehension for creating tuples or other structures",
          "coords = [(x, x*2) for x in range(3)]",
          "print(f'Coordinates: {coords}') # [(0, 0), (1, 2), (2, 4)]"
        ],
        "notes": "List comprehensions are more readable and often faster than traditional `for` loops for creating new lists. They follow the syntax `[expression for item in iterable if condition]`. The `if condition` part is optional and acts as a filter. Conditional expressions (`value_if_true if condition else value_if_false`) can be used in the `expression` part for mapping. Similar comprehensions exist for sets (`{...}`) and dictionaries (`{key: value for ...}`). They are versatile for transforming and filtering data."
      },
      {
        "name": "Dictionary Operations",
        "category": "Data Structures",
        "description": "Advanced techniques for manipulating dictionaries, including merging, default values, and counting.",
        "usage": "dict.get(key, default)",
        "examples": [
          "# Safely get a value with .get()",
          "data = {'a': 1, 'b': 2}",
          "value_c = data.get('c', 0)",
          "print(f'Value of c (default): {value_c}') # 0",
          "value_a = data.get('a', 0)",
          "print(f'Value of a: {value_a}') # 1",
          "",
          "# Merge dictionaries (Python 3.5+)",
          "dict1 = {'name': 'Alice', 'age': 30}",
          "dict2 = {'city': 'New York', 'age': 31}",
          "merged = {**dict1, **dict2}",
          "print(f'Merged dictionary: {merged}') # {'name': 'Alice', 'age': 31, 'city': 'New York'} (dict2's 'age' overwrites)",
          "",
          "# Counting frequencies using .get() or defaultdict",
          "from collections import defaultdict",
          "words = ['apple', 'banana', 'apple', 'orange', 'banana', 'apple']",
          "counts_get = {}",
          "for word in words:",
          "    counts_get[word] = counts_get.get(word, 0) + 1",
          "print(f'Counts with .get(): {counts_get}')",
          "",
          "counts_defaultdict = defaultdict(int)",
          "for word in words:",
          "    counts_defaultdict[word] += 1",
          "print(f'Counts with defaultdict: {dict(counts_defaultdict)}')",
          "",
          "# Dictionary comprehension",
          "numbers = [1, 2, 3, 4]",
          "num_squares = {x: x**2 for x in numbers}",
          "print(f'Numbers to squares: {num_squares}') # {1: 1, 2: 4, 3: 9, 4: 16}",
          "",
          "# Deleting a key",
          "my_dict = {'a': 1, 'b': 2, 'c': 3}",
          "del my_dict['b']",
          "print(f'After deleting \\'b\\': {my_dict}') # {'a': 1, 'c': 3}",
          "",
          "# .setdefault() for getting and setting a default value",
          "settings = {'theme': 'dark'}",
          "font_size = settings.setdefault('font_size', 12)",
          "print(f'Font size: {font_size}, Settings: {settings}') # Font size: 12, Settings: {'theme': 'dark', 'font_size': 12}",
          "theme_size = settings.setdefault('theme', 'light')",
          "print(f'Theme (already set): {theme_size}, Settings: {settings}') # Theme (already set): dark, Settings: {'theme': 'dark', 'font_size': 12}"
        ],
        "notes": "`.get(key, default)` safely retrieves a value, returning `default` if the key is not found (default is `None`). Dictionary merging with `**` (unpacking operator) is concise; if keys overlap, the last dictionary's value is used. `collections.defaultdict` is highly recommended for counting or grouping items, as it automatically provides a default value (e.g., `0` for `int`, `[]` for `list`) when a new key is accessed. Dictionary comprehensions provide a concise way to create dictionaries from other iterables. Use `del dict[key]` to remove a key-value pair. `.setdefault(key, default)` is useful for retrieving a value if present, or setting it to a default and returning that default if the key is missing."
      },
      {
        "name": "Functions and Classes (Basic OOP)",
        "category": "Code Organization",
        "description": "Defining functions for reusability and classes for object-oriented programming.",
        "usage": "def my_function():",
        "examples": [
          "# Basic function definition",
          "def greet(name):",
          "    \"\"\"Greets the person with the given name.\"\"\"",
          "    print(f'Hello, {name}!')",
          "",
          "greet('Alice')",
          "",
          "# Function with return value",
          "def add(a, b):",
          "    return a + b",
          "",
          "result = add(5, 3)",
          "print(f'5 + 3 = {result}')",
          "",
          "# Function with default arguments and keyword arguments",
          "def power(base, exponent=2):",
          "    return base ** exponent",
          "",
          "print(f'2 squared: {power(2)}') # 4",
          "print(f'2 cubed: {power(2, 3)}') # 8",
          "print(f'3 cubed (keyword): {power(base=3, exponent=3)}') # 27",
          "",
          "# Basic Class definition",
          "class Dog:",
          "    # Class variable (shared by all instances)",
          "    species = 'Canis familiaris'",
          "",
          "    def __init__(self, name, breed):",
          "        # Instance variables (unique to each instance)",
          "        self.name = name",
          "        self.breed = breed",
          "",
          "    def bark(self):",
          "        return f'{self.name} says Woof!'",
          "",
          "    def describe(self):",
          "        return f'{self.name} is a {self.breed} of {self.species}.'",
          "",
          "# Creating objects (instances of the class)",
          "my_dog = Dog('Buddy', 'Golden Retriever')",
          "your_dog = Dog('Lucy', 'Labrador')",
          "",
          "print(my_dog.describe())",
          "print(my_dog.bark())",
          "print(f'Lucy\\'s species: {your_dog.species}')"
        ],
        "notes": "Functions are defined with `def` and can take arguments, have default values, and return values using `return`. Docstrings (`\"\"\"Docstring\"\"\"`) explain what a function does. Classes are blueprints for creating objects. `__init__` is the constructor method, called when a new object is created. `self` refers to the instance of the class. Variables defined directly in the class are 'class variables' (shared), while those in `__init__` are 'instance variables' (per object). Methods are functions defined within a class."
      },
      {
        "name": "Modules and Packages",
        "category": "Code Organization",
        "description": "Organizing Python code into reusable modules and packages for better structure and maintainability.",
        "usage": "import module_name",
        "examples": [
          "# Assuming a file 'my_module.py' exists with: def hello(): print('Hello from my_module!')",
          "# import my_module",
          "# my_module.hello()",
          "",
          "# Importing specific functions/classes",
          "# from my_module import hello",
          "# hello()",
          "",
          "# Aliasing imports",
          "# import my_module as mm",
          "# mm.hello()",
          "",
          "# Importing all (generally discouraged for clarity)",
          "# from my_module import *",
          "# hello()",
          "",
          "# Example of a simple package structure:",
          "# my_package/",
          "#   __init__.py",
          "#   module_a.py (contains func_a)",
          "#   module_b.py (contains func_b)",
          "",
          "# To use:",
          "# from my_package import module_a",
          "# module_a.func_a()",
          "",
          "# Or:",
          "# from my_package.module_b import func_b",
          "# func_b()",
          "",
          "# Standard library examples:",
          "import math",
          "print(f'Pi: {math.pi}')",
          "print(f'Square root of 16: {math.sqrt(16)}')",
          "",
          "from collections import Counter",
          "counts = Counter(['a', 'b', 'a', 'c', 'b', 'a'])",
          "print(f'Counts: {counts}')"
        ],
        "notes": "A module is a single Python file (`.py`). A package is a collection of modules in a directory, which *must* contain an `__init__.py` file (can be empty). `import module_name` imports the whole module. `from module_name import item` imports specific items. Use `as` for aliasing to avoid name conflicts or shorten names. Importing `*` (all) is generally bad practice as it pollutes the namespace. Python's standard library provides many useful modules (e.g., `math`, `collections`, `os`, `sys`). Use `pip install` to install third-party packages."
      },
      {
        "name": "Virtual Environments",
        "category": "Development Setup",
        "description": "Creating isolated Python environments to manage project-specific dependencies without conflicts.",
        "usage": "python -m venv myenv",
        "examples": [
          "# Create a virtual environment named 'myenv'",
          "print('Creating virtual environment...')",
          "# Command to run in shell:",
          "# python -m venv myenv",
          "",
          "# Activate the virtual environment (shell commands):",
          "# On Windows (cmd): myenv\\Scripts\\activate.bat",
          "# On Windows (PowerShell): myenv\\Scripts\\Activate.ps1",
          "# On macOS/Linux: source myenv/bin/activate",
          "",
          "# Once activated, install packages:",
          "# pip install requests beautifulsoup4",
          "",
          "# List installed packages in the virtual environment:",
          "# pip freeze",
          "",
          "# Deactivate the virtual environment (shell command):",
          "# deactivate",
          "",
          "print('Virtual environment created in the current directory. Follow activation steps in your terminal.')"
        ],
        "notes": "Virtual environments (`venv` module) are essential for Python development. They create an isolated installation of Python and its packages for each project. This prevents conflicts between different projects that might require different versions of the same library. After creation, activate the environment in your terminal before installing packages. Use `pip freeze > requirements.txt` to save your project's dependencies for easy sharing and reproduction."
      },
      {
        "name": "Testing (unittest)",
        "category": "Quality Assurance",
        "description": "Writing and running unit tests to ensure code correctness and prevent regressions using the `unittest` module.",
        "usage": "import unittest; class MyTests(unittest.TestCase):",
        "examples": [
          "import unittest",
          "",
          "# Example function to test",
          "def add(a, b):",
          "    return a + b",
          "",
          "def subtract(a, b):",
          "    return a - b",
          "",
          "# Define a test class inheriting from unittest.TestCase",
          "class TestMathFunctions(unittest.TestCase):",
          "",
          "    def test_add_positive_numbers(self):",
          "        self.assertEqual(add(2, 3), 5)",
          "",
          "    def test_add_negative_numbers(self):",
          "        self.assertEqual(add(-1, -1), -2)",
          "",
          "    def test_subtract_positive_numbers(self):",
          "        self.assertEqual(subtract(5, 2), 3)",
          "",
          "    def test_subtract_zero(self):",
          "        self.assertEqual(subtract(10, 0), 10)",
          "",
          "# This block runs the tests when the script is executed directly",
          "if __name__ == '__main__':",
          "    print('Running tests...')",
          "    unittest.main(argv=['first-arg-is-ignored'], exit=False)",
          "    print('Tests finished.')",
          "",
          "# To run tests from command line (assuming file is 'test_my_app.py'):",
          "# python -m unittest test_my_app.py"
        ],
        "notes": "`unittest` is Python's built-in testing framework. Test classes inherit from `unittest.TestCase`. Test methods must start with `test_`. Use assertion methods like `self.assertEqual()`, `self.assertTrue()`, `self.assertFalse()`, `self.assertIn()`, etc., to check expected outcomes. `if __name__ == '__main__': unittest.main()` is the standard way to make tests runnable directly. `pytest` is a popular third-party alternative often preferred for its simpler syntax and features."
      },
      {
        "name": "File System Operations (pathlib)",
        "category": "File System",
        "description": "Modern, object-oriented approach to file system paths using the `pathlib` module.",
        "usage": "from pathlib import Path; p = Path('my_file.txt')",
        "examples": [
          "from pathlib import Path",
          "import os",
          "",
          "# Create a Path object",
          "p = Path('my_folder/subfolder/file.txt')",
          "print(f'Path object: {p}')",
          "",
          "# Get current working directory",
          "current_dir = Path.cwd()",
          "print(f'Current directory (Path): {current_dir}')",
          "",
          "# Create directories (like os.makedirs)",
          "new_path = Path('project/data/raw')",
          "new_path.mkdir(parents=True, exist_ok=True)",
          "print(f'Created path: {new_path.absolute()}')",
          "",
          "# Check if path exists, is a file, or is a directory",
          "if p.exists(): print(f'{p} exists.')",
          "if p.is_file(): print(f'{p} is a file.')",
          "if p.is_dir(): print(f'{p} is a directory.')",
          "",
          "# Get parts of a path",
          "file_path = Path('documents/report.docx')",
          "print(f'Name: {file_path.name}') # report.docx",
          "print(f'Stem: {file_path.stem}') # report",
          "print(f'Suffix: {file_path.suffix}') # .docx",
          "print(f'Parent: {file_path.parent}') # documents",
          "",
          "# Join paths (using / operator)",
          "combined_path = Path('logs') / 'daily' / 'access.log'",
          "print(f'Combined path: {combined_path}') # logs/daily/access.log",
          "",
          "# Write to a file",
          "output_file = Path('example.txt')",
          "output_file.write_text('Hello from pathlib!')",
          "print(f'Wrote to {output_file}')",
          "",
          "# Read from a file",
          "content = output_file.read_text()",
          "print(f'Read content: {content}')",
          "",
          "# Iterate over files in a directory",
          "print('\\nFiles in current directory (using glob):')",
          "for f in Path('.').glob('*.py'):",
          "    print(f'  {f.name}')",
          "",
          "# Change file permissions (Unix-like systems)",
          "import stat",
          "dummy_file = Path('permissions_test.txt')",
          "dummy_file.write_text('Test')",
          "print(f'Original permissions of {dummy_file}: {oct(dummy_file.stat().st_mode)}')",
          "dummy_file.chmod(0o644) # Read/write for owner, read for group/others",
          "print(f'New permissions: {oct(dummy_file.stat().st_mode)}')",
          "",
          "# Clean up created files/dirs",
          "if new_path.exists(): new_path.rmdir() # Only if empty",
          "if new_path.parent.exists(): new_path.parent.rmdir()",
          "if output_file.exists(): output_file.unlink()",
          "if dummy_file.exists(): dummy_file.unlink()"
        ],
        "notes": "`pathlib` provides an object-oriented way to interact with file paths, making code cleaner and more readable than `os.path` functions. `Path.cwd()` gets the current directory. `Path().mkdir()` creates directories with `parents=True` for nesting and `exist_ok=True` to avoid errors. Use the `/` operator to join path components. Methods like `.exists()`, `.is_file()`, `.is_dir()`, `.name`, `.stem`, `.suffix`, `.parent` simplify path introspection. `.write_text()` and `.read_text()` provide simple file I/O. `Path().glob()` performs pattern matching for files/directories. `chmod()` can change file permissions (using octal notation, often on Unix-like systems)."
      },
      {
        "name": "Set and Tuple Operations",
        "category": "Data Structures",
        "description": "Understanding and utilizing Python's `set` (unordered, unique elements) and `tuple` (ordered, immutable sequence) data types.",
        "usage": "my_set = {1, 2, 3}; my_tuple = (1, 2, 3)",
        "examples": [
          "# Set operations (unique elements, no order)",
          "set1 = {1, 2, 3, 4, 5}",
          "set2 = {4, 5, 6, 7, 8}",
          "",
          "print(f'Set 1: {set1}')",
          "print(f'Set 2: {set2}')",
          "print(f'Union (all unique elements): {set1.union(set2)}') # {1, 2, 3, 4, 5, 6, 7, 8}",
          "print(f'Intersection (common elements): {set1.intersection(set2)}') # {4, 5}",
          "print(f'Difference (in set1 but not set2): {set1.difference(set2)}') # {1, 2, 3}",
          "print(f'Symmetric Difference (elements unique to each set): {set1.symmetric_difference(set2)}') # {1, 2, 3, 6, 7, 8}",
          "print(f'Is set1 a superset of {set({1,2})}: {set1.issuperset({1, 2})}') # True",
          "print(f'Is {set({1,2})} a subset of set1: {({1,2}).issubset(set1)}') # True",
          "",
          "# Tuples (immutable sequences)",
          "my_tuple = (10, 20, 'hello', True)",
          "print(f'Tuple: {my_tuple}')",
          "print(f'First element: {my_tuple[0]}') # 10",
          "print(f'Length: {len(my_tuple)}') # 4",
          "",
          "# Tuples can be used as dictionary keys (unlike lists) because they are hashable",
          "coordinates = {(1, 2): 'Point A', (3, 4): 'Point B'}",
          "print(f'Coordinate (1,2): {coordinates[(1, 2)]}')",
          "",
          "# Unpacking tuples",
          "point = (5, 8)",
          "x, y = point",
          "print(f'Unpacked x: {x}, y: {y}')",
          "",
          "# Single element tuple (note the comma!)",
          "single_tuple = (42,)",
          "print(f'Single element tuple type: {type(single_tuple)}')",
          "",
          "# Immutable nature: try to change an element (will raise error)",
          "try:",
          "    my_tuple[0] = 99",
          "except TypeError as e:",
          "    print(f'Error trying to modify tuple: {e}')"
        ],
        "notes": "`set` objects store unordered collections of *unique* elements. They are mutable. Common uses include removing duplicates from a list, performing mathematical set operations (union, intersection, difference, subset, superset). `set()` can be used to convert an iterable to a set. `tuple` objects are ordered, immutable sequences. Once created, their elements cannot be changed. They are often used for heterogeneous data (e.g., coordinates, record-like data) or as dictionary keys because they are hashable."
      },
      {
        "name": "Decorators",
        "category": "Advanced Python",
        "description": "Functions that modify the behavior of other functions or methods without permanently altering them.",
        "usage": "@my_decorator",
        "examples": [
          "# Simple timing decorator",
          "import time",
          "import functools",
          "",
          "def timing_decorator(func):",
          "    @functools.wraps(func)",
          "    def wrapper(*args, **kwargs):",
          "        start_time = time.time()",
          "        result = func(*args, **kwargs)",
          "        end_time = time.time()",
          "        print(f'{func.__name__} took {end_time - start_time:.4f} seconds to run.')",
          "        return result",
          "    return wrapper",
          "",
          "@timing_decorator",
          "def long_running_function():",
          "    \"\"\"A function that takes a long time.\"\"\"",
          "    sum(range(10000000)) # Simulate a long operation",
          "",
          "@timing_decorator",
          "def another_task(a, b):",
          "    time.sleep(0.5)",
          "    return a + b",
          "",
          "print('Running long_running_function:')",
          "long_running_function()",
          "print('Running another_task:')",
          "res = another_task(10, 20)",
          "print(f'Result of another_task: {res}')",
          "",
          "# Decorator with arguments",
          "def repeat(num_times):",
          "    def decorator_repeat(func):",
          "        @functools.wraps(func)",
          "        def wrapper_repeat(*args, **kwargs):",
          "            for _ in range(num_times):",
          "                func(*args, **kwargs)",
          "        return wrapper_repeat",
          "    return decorator_repeat",
          "",
          "@repeat(num_times=3)",
          "def say_hello():",
          "    print('Hello!')",
          "",
          "print('\\nSaying hello multiple times:')",
          "say_hello()"
        ],
        "notes": "A decorator is a callable that takes a function as an argument and returns a new function. The `@decorator_name` syntax is syntactic sugar for `my_function = decorator_name(my_function)`. Decorators are commonly used for logging, timing, caching, access control, and retries. For decorators that accept arguments, you need a nested function structure (a 'decorator factory') that returns the actual decorator. Use `functools.wraps` within the `wrapper` function to preserve the original function's metadata (like `__name__`, `__doc__`)."
      },
      {
        "name": "Generators and Iterators",
        "category": "Advanced Python",
        "description": "Understanding iterators for sequential access and generators for memory-efficient iteration.",
        "usage": "yield keyword",
        "examples": [
          "# Basic iterator (list is an iterable, and its iterator can be obtained)",
          "my_list = [1, 2, 3]",
          "my_iterator = iter(my_list)",
          "print(f'Next from iterator: {next(my_iterator)}') # 1",
          "print(f'Next from iterator: {next(my_iterator)}') # 2",
          "try:",
          "    print(f'Next from iterator: {next(my_iterator)}') # 3",
          "    print(f'Next from iterator: {next(my_iterator)}') # Raises StopIteration",
          "except StopIteration:",
          "    print('End of iteration.')",
          "",
          "# Generator function (uses 'yield')",
          "def count_up_to(max_num):",
          "    n = 0",
          "    while n <= max_num:",
          "        yield n",
          "        n += 1",
          "",
          "print('\\nCounting with generator:')",
          "counter_generator = count_up_to(3)",
          "print(f'Next: {next(counter_generator)}') # 0",
          "print(f'Next: {next(counter_generator)}') # 1",
          "for num in counter_generator: # Continues from where it left off",
          "    print(f'Current: {num}') # 2, 3",
          "",
          "# Generator expression (like list comprehension but returns a generator)",
          "gen_expr = (x**2 for x in range(5))",
          "print(f'Generator expression: {gen_expr}')",
          "print(f'First two squares: {next(gen_expr)}, {next(gen_expr)}')",
          "print(f'Remaining squares: {list(gen_expr)}')",
          "",
          "# Infinite generator (use with caution, e.g., in a data stream)",
          "def fibonacci_sequence():",
          "    a, b = 0, 1",
          "    while True:",
          "        yield a",
          "        a, b = b, a + b",
          "",
          "fib_gen = fibonacci_sequence()",
          "print('\\nFirst 5 Fibonacci numbers:')",
          "for _ in range(5):",
          "    print(next(fib_gen))"
        ],
        "notes": "An iterator is an object that implements the iterator protocol (methods `__iter__()` and `__next__()`). `next(iterator)` retrieves the next item, raising `StopIteration` when no more items are available. Generators are a simpler way to create iterators, especially for potentially large sequences, by using the `yield` keyword in a function. When `yield` is encountered, the generator 'pauses' and returns a value; it resumes from where it left off on the next call to `next()`. Generators are memory-efficient because they produce items one by one, rather than building the entire sequence in memory. Generator expressions are a concise syntax for simple generators."
      },
      {
        "name": "Concurrency (Threading and Asyncio)",
        "category": "Performance",
        "description": "Performing multiple operations seemingly simultaneously using threads for I/O-bound tasks or asyncio for asynchronous programming.",
        "usage": "import threading; import asyncio",
        "examples": [
          "import threading",
          "import time",
          "import asyncio",
          "",
          "# Threading Example (for I/O-bound tasks like network requests)",
          "def fetch_data(url):",
          "    print(f'Starting fetch for {url}...')",
          "    time.sleep(2) # Simulate network delay",
          "    print(f'Finished fetch for {url}.')",
          "",
          "print('--- Threading Demo ---')",
          "t1 = threading.Thread(target=fetch_data, args=('http://example.com/data1',))",
          "t2 = threading.Thread(target=fetch_data, args=('http://example.com/data2',))",
          "t1.start()",
          "t2.start()",
          "t1.join() # Wait for thread t1 to complete",
          "t2.join() # Wait for thread t2 to complete",
          "print('All data fetched with threads.')",
          "",
          "# Asyncio Example (for I/O-bound tasks with non-blocking operations)",
          "async def async_fetch_data(url):",
          "    print(f'Starting async fetch for {url}...')",
          "    await asyncio.sleep(1) # Simulate non-blocking I/O",
          "    print(f'Finished async fetch for {url}.')",
          "",
          "async def main_async():",
          "    print('--- Asyncio Demo ---')",
          "    await asyncio.gather(",
          "        async_fetch_data('http://example.com/async_data1'),",
          "        async_fetch_data('http://example.com/async_data2')",
          "    )",
          "    print('All data fetched asynchronously.')",
          "",
          "# Run the asyncio event loop",
          "asyncio.run(main_async())",
          "",
          "# Threading with Locks (for shared resources)",
          "print('\\n--- Threading with Lock Demo ---')",
          "shared_counter = 0",
          "lock = threading.Lock()",
          "",
          "def increment_counter():",
          "    global shared_counter",
          "    for _ in range(100000):",
          "        with lock:",
          "            shared_counter += 1",
          "",
          "threads = [threading.Thread(target=increment_counter) for _ in range(5)]",
          "for t in threads: t.start()",
          "for t in threads: t.join()",
          "print(f'Final shared counter (with lock): {shared_counter}')"
        ],
        "notes": "`threading` module creates threads that run concurrently within the same process. It's best for I/O-bound tasks (where the program spends time waiting for external resources). Due to Python's Global Interpreter Lock (GIL), threading doesn't offer true parallel execution for CPU-bound tasks. `asyncio` is a framework for writing single-threaded concurrent code using coroutines (`async def`, `await`). It's also ideal for I/O-bound operations as it allows the program to switch tasks while waiting for I/O. `asyncio.run()` runs the top-level `async def` function. Choose `threading` for simpler blocking I/O tasks or `asyncio` for more complex, highly concurrent, and non-blocking I/O patterns. When threads share resources, use `threading.Lock` to prevent race conditions and ensure data integrity."
      },
      {
        "name": "Debugging",
        "category": "Development Tools",
        "description": "Techniques and tools for finding and fixing errors in Python code.",
        "usage": "import pdb; pdb.set_trace()",
        "examples": [
          "import pdb",
          "",
          "def calculate_total(price, quantity):",
          "    # This is where a breakpoint might go if you suspect issues",
          "    # pdb.set_trace() # Uncomment this line to start debugging here",
          "    total = price * quantity",
          "    return total",
          "",
          "item_price = 10",
          "item_quantity = '5' # This will cause a TypeError or ValueError if not handled",
          "",
          "try:",
          "    final_total = calculate_total(item_price, int(item_quantity))",
          "    print(f'Total: {final_total}')",
          "except ValueError as e:",
          "    print(f'Error: {e}. Check quantity input.')",
          "    # pdb.post_mortem() # Uncomment to enter debugger after an exception",
          "",
          "# Using print statements for basic debugging",
          "def debug_example(data):",
          "    print(f'DEBUG: Input data is {data}')",
          "    intermediate_result = data * 2",
          "    print(f'DEBUG: Intermediate result is {intermediate_result}')",
          "    return intermediate_result + 5",
          "",
          "# Example of conditional print for debugging",
          "DEBUG_MODE = True",
          "if DEBUG_MODE:",
          "    print('DEBUG_MODE is ON')",
          "debug_example(10)",
          "",
          "print('\\nTo use pdb: uncomment `pdb.set_trace()` or `pdb.post_mortem()` and run the script from terminal.')",
          "print('Common pdb commands: `n` (next line), `s` (step into), `c` (continue), `p variable` (print variable), `q` (quit).')"
        ],
        "notes": "The simplest form of debugging is using `print()` statements to inspect variable values and execution flow. For more interactive debugging, Python's built-in `pdb` (Python Debugger) module is powerful. `pdb.set_trace()` inserts a breakpoint, pausing execution and entering the debugger console. `pdb.post_mortem()` can be used inside an `except` block to start debugging at the point where an unhandled exception occurred. Integrated Development Environments (IDEs) like VS Code or PyCharm offer advanced graphical debuggers that are much easier to use than `pdb` directly in the terminal."
      },
      {
        "name": "File Operations (Advanced - shutil & tempfile)",
        "category": "I/O Operations",
        "description": "Performing high-level file operations (copying, moving, archiving) and working with temporary files and directories.",
        "usage": "import shutil; import tempfile",
        "examples": [
          "import shutil",
          "import tempfile",
          "import os",
          "",
          "# Create dummy files for demonstration",
          "with open('source.txt', 'w') as f: f.write('Hello source')",
          "os.makedirs('backup_dir', exist_ok=True)",
          "",
          "# Copy a file",
          "shutil.copy('source.txt', 'backup_dir/copy_source.txt')",
          "print('Copied source.txt to backup_dir/copy_source.txt')",
          "",
          "# Move/Rename a file",
          "shutil.move('source.txt', 'moved_source.txt')",
          "print('Moved source.txt to moved_source.txt')",
          "",
          "# Copy an entire directory (recursive)",
          "os.makedirs('original_data', exist_ok=True)",
          "with open('original_data/file1.txt', 'w') as f: f.write('data')",
          "shutil.copytree('original_data', 'copied_data')",
          "print('Copied original_data to copied_data')",
          "",
          "# Create and use a temporary file",
          "with tempfile.TemporaryFile(mode='w+') as fp:",
          "    fp.write('Temporary file content\\n')",
          "    fp.seek(0)",
          "    print(f'Read from temp file: {fp.read().strip()}')",
          "",
          "# Create and use a temporary directory",
          "with tempfile.TemporaryDirectory() as tmpdir:",
          "    print(f'Created temporary directory: {tmpdir}')",
          "    temp_file_path = os.path.join(tmpdir, 'temp_report.txt')",
          "    with open(temp_file_path, 'w') as f: f.write('Report data')",
          "    print(f'Wrote to: {temp_file_path}')",
          "print('Temporary directory and its contents are automatically cleaned up.')",
          "",
          "# Create a zip archive",
          "shutil.make_archive('my_archive', 'zip', 'copied_data')",
          "print('Created my_archive.zip')",
          "",
          "# Clean up created files/dirs",
          "if os.path.exists('moved_source.txt'): os.remove('moved_source.txt')",
          "if os.path.exists('backup_dir'): shutil.rmtree('backup_dir')",
          "if os.path.exists('original_data'): shutil.rmtree('original_data')",
          "if os.path.exists('copied_data'): shutil.rmtree('copied_data')",
          "if os.path.exists('my_archive.zip'): os.remove('my_archive.zip')"
        ],
        "notes": "The `shutil` module provides high-level file operations (copying, moving, deleting files/directories, archiving). `shutil.copy()` copies files, `shutil.move()` moves/renames files/directories. `shutil.copytree()` copies directories recursively. `shutil.rmtree()` removes directories and their contents (use with extreme caution!). The `tempfile` module creates temporary files and directories that are automatically cleaned up, useful for intermediate data storage. `TemporaryFile()` creates a file, `TemporaryDirectory()` creates a directory."
      },
      {
        "name": "Object-Oriented Programming (Advanced)",
        "category": "Code Organization",
        "description": "Exploring more advanced OOP concepts: inheritance, polymorphism, abstract base classes, class methods, and static methods.",
        "usage": "class Child(Parent):",
        "examples": [
          "# Inheritance and Polymorphism",
          "class Animal:",
          "    def __init__(self, name):",
          "        self.name = name",
          "    def make_sound(self):",
          "        raise NotImplementedError('Subclasses must implement this method')",
          "    def describe(self):",
          "        return f'This is an animal named {self.name}.'",
          "",
          "class Dog(Animal):",
          "    def __init__(self, name, breed):",
          "        super().__init__(name)",
          "        self.breed = breed",
          "    def make_sound(self):",
          "        return 'Woof!'",
          "    def describe(self): # Overriding parent method",
          "        return f'{self.name} is a {self.breed} dog. {super().describe()}'",
          "",
          "class Cat(Animal):",
          "    def make_sound(self):",
          "        return 'Meow!'",
          "",
          "my_dog = Dog('Buddy', 'Golden')",
          "my_cat = Cat('Whiskers')",
          "animals = [my_dog, my_cat]",
          "for animal in animals:",
          "    print(f'{animal.name} says: {animal.make_sound()}')",
          "    print(animal.describe())",
          "",
          "# Abstract Base Classes (ABCs) - enforces method implementation",
          "from abc import ABC, abstractmethod",
          "",
          "class Shape(ABC):",
          "    @abstractmethod",
          "    def area(self):",
          "        pass",
          "    @abstractmethod",
          "    def perimeter(self):",
          "        pass",
          "",
          "class Circle(Shape):",
          "    def __init__(self, radius):",
          "        self.radius = radius",
          "    def area(self):",
          "        return 3.14159 * self.radius ** 2",
          "    def perimeter(self):",
          "        return 2 * 3.14159 * self.radius",
          "",
          "# try:",
          "#     s = Shape() # This would raise TypeError because Shape is abstract",
          "# except TypeError as e:",
          "#     print(f'Cannot instantiate abstract class: {e}')",
          "c = Circle(5)",
          "print(f'Circle area: {c.area()}, perimeter: {c.perimeter()}')",
          "",
          "# Class Methods and Static Methods",
          "class MyClass:",
          "    count = 0 # Class variable",
          "",
          "    def __init__(self, value):",
          "        self.value = value",
          "        MyClass.count += 1",
          "",
          "    @classmethod",
          "    def create_default(cls):",
          "        # cls refers to the class itself (e.g., MyClass)",
          "        return cls(0)",
          "",
          "    @staticmethod",
          "    def utility_method(x, y):",
          "        # Does not access instance or class state",
          "        return x * y",
          "",
          "obj1 = MyClass(10)",
          "obj2 = MyClass.create_default() # Using a class method",
          "print(f'Total instances created: {MyClass.count}') # 2",
          "print(f'Utility result: {MyClass.utility_method(5, 5)}') # 25"
        ],
        "notes": "`Inheritance` allows a class (child/subclass) to inherit attributes and methods from another class (parent/superclass). `super().__init__()` calls the parent's constructor. `Polymorphism` allows objects of different classes to be treated as objects of a common superclass (e.g., `animal.make_sound()` behaves differently for `Dog` and `Cat`). `Abstract Base Classes (ABCs)` use `abc` module and `@abstractmethod` to define methods that *must* be implemented by subclasses, preventing direct instantiation. `@classmethod` methods receive the class itself (`cls`) as the first argument, often used as alternative constructors. `@staticmethod` methods are regular functions within a class that don't need access to `self` or `cls`."
      },
      {
        "name": "Concurrency (Multiprocessing)",
        "category": "Performance",
        "description": "Achieving true parallelism for CPU-bound tasks by running operations in separate processes, bypassing Python's GIL.",
        "usage": "import multiprocessing; p = multiprocessing.Process(target=func)",
        "examples": [
          "import multiprocessing",
          "import time",
          "import os",
          "",
          "def cpu_bound_task(name):",
          "    print(f'Process {name}: Starting CPU-bound task (PID: {os.getpid()})...')",
          "    sum(i*i for i in range(10**7)) # Intensive calculation",
          "    print(f'Process {name}: Finished CPU-bound task.')",
          "",
          "if __name__ == '__main__':",
          "    print('--- Multiprocessing Demo ---')",
          "    p1 = multiprocessing.Process(target=cpu_bound_task, args=('Worker 1',))",
          "    p2 = multiprocessing.Process(target=cpu_bound_task, args=('Worker 2',))",
          "",
          "    start_time = time.time()",
          "    p1.start()",
          "    p2.start()",
          "",
          "    p1.join()",
          "    p2.join()",
          "    end_time = time.time()",
          "    print(f'All tasks finished in {end_time - start_time:.4f} seconds.')",
          "",
          "    # Using a Pool for managing multiple workers",
          "    def square(x):",
          "        time.sleep(0.1) # Simulate some work",
          "        return x * x",
          "",
          "    print('\\n--- Multiprocessing Pool Demo ---')",
          "    with multiprocessing.Pool(processes=4) as pool:",
          "        results = pool.map(square, range(10))",
          "    print(f'Pool results: {results}')",
          "",
          "    # Sharing data between processes (Queue)",
          "    def worker_queue(q, data_item):",
          "        q.put(data_item * 2)",
          "",
          "    q = multiprocessing.Queue()",
          "    p3 = multiprocessing.Process(target=worker_queue, args=(q, 5))",
          "    p3.start()",
          "    p3.join()",
          "    print(f'Result from queue: {q.get()}')",
          "",
          "    # Sharing data between processes (Value/Array for primitive types)",
          "    shared_val = multiprocessing.Value('i', 0) # 'i' for signed int",
          "    shared_arr = multiprocessing.Array('i', range(5))",
          "",
          "    def worker_shared_data(value, arr):",
          "        value.value += 1",
          "        for i in range(len(arr)): arr[i] *= 2",
          "",
          "    p4 = multiprocessing.Process(target=worker_shared_data, args=(shared_val, shared_arr))",
          "    p4.start()",
          "    p4.join()",
          "    print(f'Shared value after processing: {shared_val.value}')",
          "    print(f'Shared array after processing: {list(shared_arr)}')",
          ""
        ],
        "notes": "`multiprocessing` creates new processes, each with its own Python interpreter and memory space. This is crucial for CPU-bound tasks in Python because it bypasses the Global Interpreter Lock (GIL), allowing true parallel execution on multi-core processors. `multiprocessing.Process` creates and manages individual processes. `start()` begins execution, `join()` waits for completion. `multiprocessing.Pool` provides a convenient way to manage a pool of worker processes for parallelizing tasks (e.g., `map()` applies a function to items in parallel). Data must be explicitly passed between processes using mechanisms like `multiprocessing.Queue` for message passing, or `multiprocessing.Value` and `multiprocessing.Array` for sharing primitive types or arrays (though these require careful synchronization for complex data)."
      },
      {
        "name": "Context Managers ('with' statement)",
        "category": "Code Organization",
        "description": "Managing resources (like files, network connections) safely and automatically using the `with` statement.",
        "usage": "with resource_acquisition_expression as variable:",
        "examples": [
          "# Basic file handling with 'with' (resource automatically closed)",
          "print('--- File Context Manager ---')",
          "try:",
          "    with open('auto_close.txt', 'w') as f:",
          "        f.write('This file will be automatically closed.')",
          "    print('File written and closed automatically.')",
          "    with open('auto_close.txt', 'r') as f:",
          "        print(f'Content: {f.read().strip()}')",
          "except Exception as e:",
          "    print(f'Error with file: {e}')",
          "finally:",
          "    if os.path.exists('auto_close.txt'): os.remove('auto_close.txt')",
          "",
          "# Creating a custom context manager using contextlib.contextmanager",
          "from contextlib import contextmanager",
          "import os",
          "",
          "@contextmanager",
          "def change_dir(new_path):",
          "    \"\"\"Context manager to temporarily change the current working directory.\"\"\"",
          "    old_path = os.getcwd()",
          "    try:",
          "        os.chdir(new_path)",
          "        print(f'Changed directory to: {new_path}')",
          "        yield # Code inside 'with' block executes here",
          "    finally:",
          "        os.chdir(old_path)",
          "        print(f'Restored directory to: {old_path}')",
          "",
          "print('\\n--- Custom Context Manager Demo ---')",
          "current_cwd = os.getcwd()",
          "print(f'Before: {current_cwd}')",
          "os.makedirs('temp_work_dir', exist_ok=True)",
          "with change_dir('temp_work_dir'):",
          "    print(f'Inside context: {os.getcwd()}')",
          "    with open('inside_temp.txt', 'w') as f: f.write('temp content')",
          "print(f'After: {os.getcwd()}')",
          "",
          "# Clean up",
          "if os.path.exists('temp_work_dir'): shutil.rmtree('temp_work_dir')"
        ],
        "notes": "The `with` statement simplifies resource management (e.g., files, locks, network connections) by ensuring that setup and teardown code is executed automatically. It works with objects that implement the context manager protocol (`__enter__()` for setup, `__exit__()` for teardown). For creating custom context managers, the `contextlib` module provides convenient tools like the `@contextmanager` decorator, which turns a simple generator function into a context manager. The `yield` statement within the decorated function is where the code inside the `with` block will execute."
      },
      {
        "name": "Functional Programming Concepts",
        "category": "Programming Paradigms",
        "description": "Applying functional programming techniques: `map`, `filter`, `lambda` functions, and `reduce`.",
        "usage": "map(func, iterable); filter(func, iterable); lambda args: expression",
        "examples": [
          "# Lambda functions (anonymous functions)",
          "add_one = lambda x: x + 1",
          "print(f'Lambda add_one(5): {add_one(5)}') # 6",
          "",
          "multiply = lambda x, y: x * y",
          "print(f'Lambda multiply(4, 3): {multiply(4, 3)}') # 12",
          "",
          "# map() - applies a function to all items in an input list",
          "numbers = [1, 2, 3, 4, 5]",
          "squared_numbers_map = list(map(lambda x: x**2, numbers))",
          "print(f'Squared numbers (map): {squared_numbers_map}') # [1, 4, 9, 16, 25]",
          "",
          "# filter() - constructs an iterator from elements of an iterable for which a function returns true",
          "even_numbers_filter = list(filter(lambda x: x % 2 == 0, numbers))",
          "print(f'Even numbers (filter): {even_numbers_filter}') # [2, 4]",
          "",
          "# reduce() - applies a function of two arguments cumulatively to the items of a sequence",
          "from functools import reduce",
          "sum_of_numbers = reduce(lambda x, y: x + y, numbers)",
          "print(f'Sum (reduce): {sum_of_numbers}') # 15",
          "",
          "max_number = reduce(lambda x, y: x if x > y else y, numbers)",
          "print(f'Max (reduce): {max_number}') # 5"
        ],
        "notes": "`lambda` creates small, anonymous functions. They are restricted to a single expression. `map(function, iterable)` applies `function` to every item of `iterable` and returns an iterator of the results. `filter(function, iterable)` constructs an iterator from elements of `iterable` for which `function` returns true. `functools.reduce(function, iterable)` applies `function` (which must take two arguments) cumulatively to the items of `iterable` from left to right to reduce the iterable to a single value. While powerful, list comprehensions often provide a more readable alternative to `map` and `filter` for common use cases."
      },
      {
        "name": "Data Structures (Advanced - collections module)",
        "category": "Data Structures",
        "description": "Specialized container datatypes providing alternatives to Python’s general purpose built-in containers.",
        "usage": "from collections import Counter, deque, OrderedDict",
        "examples": [
          "from collections import Counter, deque, OrderedDict, namedtuple",
          "",
          "# Counter - counts hashable objects",
          "word_list = ['apple', 'banana', 'apple', 'orange', 'banana', 'apple', 'grape']",
          "word_counts = Counter(word_list)",
          "print(f'Word counts: {word_counts}') # Counter({'apple': 3, 'banana': 2, 'orange': 1, 'grape': 1})",
          "print(f'Most common 2 words: {word_counts.most_common(2)}') # [('apple', 3), ('banana', 2)]",
          "",
          "# deque (double-ended queue) - efficient appends and pops from both ends",
          "d = deque('ghi')",
          "d.append('j')",
          "d.appendleft('f')",
          "print(f'Deque: {d}') # deque(['f', 'g', 'h', 'i', 'j'])",
          "print(f'Popped right: {d.pop()}') # j",
          "print(f'Popped left: {d.popleft()}') # f",
          "",
          "# OrderedDict (deprecated in Python 3.7+ as dict remembers insertion order)",
          "# Still useful if you need to maintain order in older Python versions or serialize to older JSON formats",
          "od = OrderedDict()",
          "od['a'] = 1",
          "od['b'] = 2",
          "od['c'] = 3",
          "print(f'OrderedDict: {od}')",
          "normal_dict = {'a': 1, 'b': 2, 'c': 3}",
          "print(f'Normal dict (insertion order guaranteed in Python 3.7+): {normal_dict}')",
          "",
          "# namedtuple - factory function for creating tuple subclasses with named fields",
          "Point = namedtuple('Point', ['x', 'y'])",
          "p1 = Point(10, 20)",
          "print(f'Namedtuple p1: {p1}') # Point(x=10, y=20)",
          "print(f'Access by name: {p1.x}, {p1.y}') # 10, 20",
          "print(f'Access by index: {p1[0]}, {p1[1]}') # 10, 20"
        ],
        "notes": "The `collections` module provides specialized data structures. `Counter` is a subclass of `dict` for counting hashable objects. `deque` is a list-like container with fast appends and pops on either end. `OrderedDict` (while less critical in Python 3.7+) maintains insertion order. `namedtuple` creates immutable tuple-like objects with named fields, improving readability over regular tuples. Other useful collections include `defaultdict` (revisited in Dictionary Operations) and `ChainMap`."
      },
      {
        "name": "Data Analysis (Pandas & NumPy Basics)",
        "category": "Data Science",
        "description": "Introduction to fundamental data analysis libraries for numerical operations and tabular data manipulation.",
        "usage": "import pandas as pd; import numpy as np",
        "examples": [
          "# Install these libraries if you haven't: pip install pandas numpy matplotlib seaborn",
          "import pandas as pd",
          "import numpy as np",
          "",
          "# NumPy - numerical operations",
          "arr = np.array([1, 2, 3, 4, 5])",
          "print(f'NumPy Array: {arr}')",
          "print(f'Array sum: {np.sum(arr)}')",
          "print(f'Array mean: {np.mean(arr)}')",
          "matrix = np.array([[1, 2], [3, 4]])",
          "print(f'\\nMatrix:\\n{matrix}')",
          "print(f'Matrix multiplication (dot product):\\n{np.dot(matrix, matrix)}')",
          "",
          "# Pandas - tabular data (DataFrame)",
          "data = {",
          "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],",
          "    'Age': [25, 30, 35, 28],",
          "    'City': ['New York', 'London', 'Paris', 'New York']",
          "}",
          "df = pd.DataFrame(data)",
          "print(f'\\nDataFrame:\\n{df}')",
          "",
          "# Basic DataFrame operations",
          "print(f'\\nSelected column (Age):\\n{df[\"Age\"]}')",
          "print(f'\\nFiltered (Age > 28):\\n{df[df[\"Age\"] > 28]}')",
          "print(f'\\nGrouped by City:\\n{df.groupby(\"City\")[\"Age\"].mean()}')",
          "",
          "# Load data from CSV (requires a dummy.csv file for example)",
          "with open('dummy.csv', 'w', newline='') as f:",
          "    f.write('id,value\\n1,10\\n2,20\\n3,30')",
          "try:",
          "    loaded_df = pd.read_csv('dummy.csv')",
          "    print(f'\\nLoaded from CSV:\\n{loaded_df}')",
          "except Exception as e:",
          "    print(f'Could not load dummy.csv: {e}')",
          "finally:",
          "    if os.path.exists('dummy.csv'): os.remove('dummy.csv')"
        ],
        "notes": "`NumPy` (Numerical Python) is the foundational library for numerical computing, providing powerful array objects and mathematical functions. `Pandas` is built on NumPy and provides `DataFrame` objects for tabular data, making data manipulation, cleaning, and analysis highly efficient. It's widely used for tasks like data loading (CSV, Excel), cleaning, transformation, and aggregation (`groupby`). Both libraries are fundamental for data science in Python."
      },
      {
        "name": "Data Visualization (Matplotlib & Seaborn Basics)",
        "category": "Data Science",
        "description": "Creating basic plots and visualizations using `matplotlib` and `seaborn`.",
        "usage": "import matplotlib.pyplot as plt; import seaborn as sns",
        "examples": [
          "import matplotlib.pyplot as plt",
          "import seaborn as sns",
          "import numpy as np",
          "import pandas as pd",
          "",
          "# Matplotlib - Basic Line Plot",
          "x = np.linspace(0, 10, 100)",
          "y = np.sin(x)",
          "plt.figure(figsize=(8, 4))",
          "plt.plot(x, y)",
          "plt.title('Sine Wave')",
          "plt.xlabel('X-axis')",
          "plt.ylabel('Y-axis')",
          "plt.grid(True)",
          "# plt.show() # Uncomment to display the plot",
          "plt.savefig('sine_wave.png')",
          "print('Saved sine_wave.png')",
          "",
          "# Matplotlib - Scatter Plot",
          "np.random.seed(42)",
          "x_scatter = np.random.rand(50)",
          "y_scatter = 2 * x_scatter + np.random.rand(50) * 0.5",
          "plt.figure(figsize=(8, 4))",
          "plt.scatter(x_scatter, y_scatter)",
          "plt.title('Scatter Plot')",
          "plt.xlabel('Feature 1')",
          "plt.ylabel('Feature 2')",
          "# plt.show() # Uncomment to display the plot",
          "plt.savefig('scatter_plot.png')",
          "print('Saved scatter_plot.png')",
          "",
          "# Seaborn - Enhanced statistical plots (built on matplotlib)",
          "data = sns.load_dataset('iris')",
          "plt.figure(figsize=(8, 5))",
          "sns.histplot(data=data, x='sepal_length', hue='species', kde=True)",
          "plt.title('Distribution of Sepal Length by Species')",
          "# plt.show() # Uncomment to display the plot",
          "plt.savefig('iris_hist.png')",
          "print('Saved iris_hist.png')",
          "",
          "# Clean up saved plots",
          "if os.path.exists('sine_wave.png'): os.remove('sine_wave.png')",
          "if os.path.exists('scatter_plot.png'): os.remove('scatter_plot.png')",
          "if os.path.exists('iris_hist.png'): os.remove('iris_hist.png')"
        ],
        "notes": "`Matplotlib` is the foundational plotting library in Python, offering extensive control over plots. `pyplot` is its most commonly used module for quick plotting. `Seaborn` is a higher-level data visualization library built on Matplotlib. It provides a more convenient interface for creating attractive and informative statistical graphics. Both require installation (`pip install matplotlib seaborn`). Use `plt.show()` to display the plot (it blocks execution until closed) and `plt.savefig()` to save it. Always call `plt.figure()` for new plots or `plt.clf()` to clear the current figure if you're not showing them interactively."
      },
      {
        "name": "Serialization (Pickle & YAML)",
        "category": "Data Processing",
        "description": "Converting Python objects into a byte stream (serialization) for storage or transmission, and back again (deserialization).",
        "usage": "import pickle; import yaml",
        "examples": [
          "import pickle",
          "import os",
          "",
          "# Pickle - Serialize Python objects",
          "data_to_pickle = {",
          "    'name': 'Python Object',",
          "    'value': [1, 2, 3, {'nested': 'dict'}],",
          "    'callable': lambda x: x*2 # Can even pickle some callables",
          "}",
          "",
          "pickle_file = 'my_object.pkl'",
          "with open(pickle_file, 'wb') as f:",
          "    pickle.dump(data_to_pickle, f)",
          "print(f'Object pickled to {pickle_file}')",
          "",
          "# Unpickle the object",
          "with open(pickle_file, 'rb') as f:",
          "    loaded_data = pickle.load(f)",
          "print(f'Unpickled data[\"name\"]: {loaded_data[\"name\"]}')",
          "print(f'Unpickled data[\"callable\"](5): {loaded_data[\"callable\"](5)}')",
          "",
          "# YAML (PyYAML library) - human-readable serialization",
          "# Install with: pip install pyyaml",
          "try:",
          "    import yaml",
          "    yaml_data = {",
          "        'server': 'localhost',",
          "        'port': 8080,",
          "        'users': ['admin', 'guest']",
          "    }",
          "    yaml_file = 'config.yaml'",
          "    with open(yaml_file, 'w') as f:",
          "        yaml.dump(yaml_data, f, default_flow_style=False)",
          "    print(f'Object serialized to YAML: {yaml_file}')",
          "",
          "    with open(yaml_file, 'r') as f:",
          "        loaded_yaml = yaml.safe_load(f)",
          "    print(f'Loaded YAML data: {loaded_yaml}')",
          "",
          "except ImportError:",
          "    print('\\nPyYAML not installed. Install with: pip install pyyaml')",
          "except Exception as e:",
          "    print(f'Error with YAML: {e}')",
          "finally:",
          "    if os.path.exists(pickle_file): os.remove(pickle_file)",
          "    if os.path.exists('config.yaml'): os.remove('config.yaml')"
        ],
        "notes": "`pickle` is Python's standard module for serializing (pickling) and deserializing (unpickling) Python objects. It can handle most Python objects, including custom classes and functions. Pickled data is specific to Python and not human-readable; it's also not secure against malicious data. `YAML` (Yet Another Markup Language) is a human-friendly data serialization standard. The `PyYAML` library (`pip install pyyaml`) allows reading and writing YAML files. Use `yaml.safe_load()` to mitigate security risks when loading untrusted YAML. YAML is often preferred over JSON for configuration files due to its readability."
      },
      {
        "name": "System Information (platform & sys)",
        "category": "System",
        "description": "Retrieving detailed information about the Python interpreter and the underlying operating system.",
        "usage": "import sys; import platform",
        "examples": [
          "import sys",
          "import platform",
          "",
          "# sys module for interpreter-specific info",
          "print('--- sys module ---')",
          "print(f'Python Version: {sys.version}')",
          "print(f'Python Executable: {sys.executable}')",
          "print(f'Platform (sys): {sys.platform}')",
          "print(f'Module Search Path (first 3): {sys.path[:3]}')",
          "print(f'Max recursion depth: {sys.getrecursionlimit()}')",
          "",
          "# platform module for OS/hardware info",
          "print('\\n--- platform module ---')",
          "print(f'Operating System: {platform.system()}')",
          "print(f'OS Release: {platform.release()}')",
          "print(f'OS Version: {platform.version()}')",
          "print(f'Architecture: {platform.machine()}')",
          "print(f'Processor: {platform.processor()}')",
          "print(f'Node Name (hostname): {platform.node()}')",
          "print(f'Python Implementation: {platform.python_implementation()}')",
          "print(f'Platform complete: {platform.platform()}')"
        ],
        "notes": "The `sys` module provides access to system-specific parameters and functions related to the Python interpreter (e.g., version, executable path, module search path). The `platform` module provides access to underlying platform's identifying data (e.g., OS type, release, architecture, processor information). These modules are useful for writing cross-platform compatible scripts and for debugging environment issues."
      },
      {
        "name": "Networking (Socket Programming)",
        "category": "Network",
        "description": "Implementing basic network communication using sockets for client-server applications.",
        "usage": "import socket",
        "examples": [
          "import socket",
          "import threading",
          "import time",
          "",
          "# Simple TCP Server",
          "def run_server():",
          "    host = '127.0.0.1'",
          "    port = 65432",
          "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:",
          "        s.bind((host, port))",
          "        s.listen()",
          "        print(f'Server listening on {host}:{port}')",
          "        conn, addr = s.accept()",
          "        with conn:",
          "            print(f'Connected by {addr}')",
          "            data = conn.recv(1024)",
          "            print(f'Received: {data.decode()}')",
          "            conn.sendall(b'Hello from server!')",
          "    print('Server closed.')",
          "",
          "# Simple TCP Client",
          "def run_client():",
          "    host = '127.0.0.1'",
          "    port = 65432",
          "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:",
          "        s.connect((host, port))",
          "        s.sendall(b'Hello from client!')",
          "        data = s.recv(1024)",
          "        print(f'Client received: {data.decode()}')",
          "    print('Client closed.')",
          "",
          "if __name__ == '__main__':",
          "    # Start server in a separate thread",
          "    server_thread = threading.Thread(target=run_server)",
          "    server_thread.start()",
          "    time.sleep(1) # Give server a moment to start",
          "",
          "    # Run client",
          "    run_client()",
          "",
          "    server_thread.join() # Wait for server thread to finish"
        ],
        "notes": "The `socket` module provides low-level network communication interfaces. TCP sockets (`socket.SOCK_STREAM`) provide reliable, connection-oriented communication, while UDP sockets (`socket.SOCK_DGRAM`) provide unreliable, connectionless communication. For a server, `bind()` associates the socket with an address, `listen()` enables accepting connections, and `accept()` waits for a client connection. For a client, `connect()` establishes a connection to a server. `sendall()` sends data, and `recv()` receives data. Data is typically sent as bytes, so use `encode()` and `decode()` for strings. For concurrent servers, threads or asyncio are often used to handle multiple client connections."
      },
      {
        "name": "Web Scraping (BeautifulSoup & Requests)",
        "category": "Web Development",
        "description": "Extracting data from HTML and XML documents using `BeautifulSoup` and `requests` for fetching web pages.",
        "usage": "import requests; from bs4 import BeautifulSoup",
        "examples": [
          "import requests",
          "from bs4 import BeautifulSoup",
          "",
          "# Simple web page fetching and parsing",
          "url = 'http://quotes.toscrape.com/' # A website designed for scraping",
          "try:",
          "    response = requests.get(url)",
          "    response.raise_for_status()",
          "    soup = BeautifulSoup(response.text, 'html.parser')",
          "",
          "    # Find all quotes on the page",
          "    quotes = soup.find_all('div', class_='quote')",
          "    print('--- Quotes from quotes.toscrape.com ---')",
          "    for quote in quotes:",
          "        text = quote.find('span', class_='text').text",
          "        author = quote.find('small', class_='author').text",
          "        tags = [tag.text for tag in quote.find('div', class_='tags').find_all('a', class_='tag')]",
          "        print(f'\\nQuote: {text}')",
          "        print(f'Author: {author}')",
          "        print(f'Tags: {', '.join(tags)}')",
          "",
          "    # Find specific elements, e.g., the page title",
          "    page_title = soup.find('h1').text.strip()",
          "    print(f'\\nPage Title: {page_title}')",
          "",
          "except requests.exceptions.RequestException as e:",
          "    print(f'Error fetching URL: {e}')",
          "except Exception as e:",
          "    print(f'Error parsing content: {e}')",
          "",
          "# Navigating the parse tree",
          "html_doc = \"\"\"",
          "<div id=\"main\">",
          "    <p class=\"intro\">Hello</p>",
          "    <p class=\"content\">World</p>",
          "</div>",
          "\"\"\"",
          "soup2 = BeautifulSoup(html_doc, 'html.parser')",
          "main_div = soup2.find('div', id='main')",
          "if main_div:",
          "    first_p = main_div.find('p')",
          "    print(f'\\nFirst paragraph in main div: {first_p.text}')",
          "    next_p = first_p.find_next_sibling('p')",
          "    if next_p: print(f'Next sibling paragraph: {next_p.text}')"
        ],
        "notes": "`requests` is used to fetch the raw HTML content from a URL. `BeautifulSoup` (`bs4`) is a library for parsing HTML and XML documents. It creates a parse tree that allows you to navigate, search, and modify the content. Key methods: `BeautifulSoup(html_content, 'html.parser')` to parse, `find()` to find the first matching tag, `find_all()` to find all matching tags. You can search by tag name, attributes (e.g., `class_`, `id`), and text content. Navigation methods like `.parent`, `.children`, `.next_sibling`, `.previous_sibling` help traverse the tree. Always respect `robots.txt` and website terms of service when scraping."
      },
      {
        "name": "Type Hinting",
        "category": "Development Tools",
        "description": "Adding type annotations to Python code to improve readability, enable static analysis, and enhance developer tooling.",
        "usage": "def func(arg: type) -> return_type:",
        "examples": [
          "# Basic type hints for function arguments and return values",
          "def greet(name: str) -> str:",
          "    return f'Hello, {name}'",
          "",
          "print(f'Greeting: {greet(\"World\")}')",
          "# print(greet(123)) # MyPy would warn about this",
          "",
          "# Type hints for variables",
          "age: int = 30",
          "temperature: float = 25.5",
          "is_active: bool = True",
          "",
          "# Using types from the 'typing' module for complex structures",
          "from typing import List, Dict, Tuple, Optional, Union, Any, Callable",
          "",
          "def process_list(data: List[int]) -> List[int]:",
          "    return [x * 2 for x in data]",
          "",
          "print(f'Processed list: {process_list([1, 2, 3])}')",
          "",
          "def get_user_data(user_id: int) -> Optional[Dict[str, Union[str, int]]]:",
          "    users = {1: {'name': 'Alice', 'age': 30}}",
          "    return users.get(user_id)",
          "",
          "user_info = get_user_data(1)",
          "if user_info: print(f'User info: {user_info}')",
          "else: print('User not found.')",
          "",
          "def apply_func(func: Callable[[int, int], int], a: int, b: int) -> int:",
          "    return func(a, b)",
          "",
          "result = apply_func(lambda x, y: x + y, 5, 10)",
          "print(f'Apply func result: {result}')",
          "",
          "# Type aliases for complex types",
          "UserId = int",
          "Response = Dict[str, Union[str, int, List[Any]]]",
          "",
          "def fetch_response(user_id: UserId) -> Response:",
          "    return {'status': 'success', 'data': {'id': user_id, 'items': []}}"
        ],
        "notes": "Type hints (PEP 484) are not enforced at runtime but are used by static analysis tools (like MyPy) and IDEs to catch errors and improve code readability and maintainability. The `typing` module provides special types for lists (`List[int]`), dictionaries (`Dict[str, int]`), tuples (`Tuple[int, str]`), optional values (`Optional[str]`), multiple possible types (`Union[str, int]`), and any type (`Any`). `Callable` defines the type of a function. Type aliases improve readability for complex type signatures. Using type hints is highly recommended for larger Python projects."
      },
      {
        "name": "Testing (Pytest)",
        "category": "Quality Assurance",
        "description": "Writing and running tests using the popular `pytest` framework, known for its simplicity and powerful features.",
        "usage": "import pytest; def test_function(): assert ...",
        "examples": [
          "# Install Pytest: pip install pytest",
          "",
          "# Example functions to test (e.g., in a file named `my_module.py`)",
          "def increment(x):",
          "    return x + 1",
          "",
          "def divide(a, b):",
          "    if b == 0: raise ValueError('Cannot divide by zero')",
          "    return a / b",
          "",
          "# Test file content (e.g., in a file named `test_my_module.py`)",
          "# import pytest",
          "# from my_module import increment, divide # assuming my_module.py exists",
          "",
          "# def test_increment_positive():",
          "#     assert increment(3) == 4",
          "",
          "# def test_increment_zero():",
          "#     assert increment(0) == 1",
          "",
          "# def test_divide_by_zero():",
          "#     with pytest.raises(ValueError, match='Cannot divide by zero'):",
          "#         divide(10, 0)",
          "",
          "# Parameterized testing with @pytest.mark.parametrize",
          "# @pytest.mark.parametrize(\"input, expected\", [",
          "#    (0, 0),",
          "#    (1, 1),",
          "#    (-1, 1),",
          "#    (5, 25),",
          "# ])",
          "# def test_absolute_value(input, expected):",
          "#    assert abs(input) == expected",
          "",
          "# Fixtures for setting up test data",
          "# @pytest.fixture",
          "# def sample_data():",
          "#     return [10, 20, 30]",
          "",
          "# def test_sum_sample_data(sample_data):",
          "#     assert sum(sample_data) == 60",
          "",
          "print('Pytest examples are commented out to avoid errors if Pytest is not installed or modules are not present.')",
          "print('Save the test functions in a file starting with `test_` (e.g., `test_my_module.py`).')",
          "print('Run from terminal: `pytest` or `pytest test_my_module.py`')"
        ],
        "notes": "`pytest` is a popular and powerful testing framework. It automatically discovers tests (files starting with `test_`, functions starting with `test_`). Assertions are simple Python `assert` statements. `pytest.raises` is used to test that a specific exception is raised. `@pytest.mark.parametrize` allows running the same test function with different sets of inputs, simplifying test cases. `pytest.fixture` provides a way to define reusable setup and teardown code for tests, making tests more modular and maintainable. It's often preferred over `unittest` for its conciseness and rich feature set."
      },
      {
        "name": "Dataclasses",
        "category": "Data Structures",
        "description": "Creating simple data-holding classes with minimal boilerplate using the `dataclasses` module (Python 3.7+).",
        "usage": "from dataclasses import dataclass; @dataclass class MyData:",
        "examples": [
          "from dataclasses import dataclass, field",
          "",
          "# Basic dataclass",
          "@dataclass",
          "class Product:",
          "    name: str",
          "    price: float",
          "    quantity: int = 0 # Default value",
          "",
          "p1 = Product('Laptop', 1200.0)",
          "p2 = Product('Mouse', 25.50, 10)",
          "print(f'Product 1: {p1}') # Product(name='Laptop', price=1200.0, quantity=0)",
          "print(f'Product 2: {p2}')",
          "print(f'Product name: {p1.name}')",
          "",
          "# Dataclass with __post_init__ and default_factory",
          "@dataclass",
          "class InventoryItem:",
          "    name: str",
          "    unit_price: float",
          "    quantity_on_hand: int = 0",
          "    # Use field for mutable defaults or custom initialization",
          "    properties: dict = field(default_factory=dict)",
          "",
          "    def __post_init__(self):",
          "        # Method called after __init__ for additional setup/validation",
          "        if self.unit_price < 0:",
          "            raise ValueError('Unit price cannot be negative')",
          "        self.total_cost = self.unit_price * self.quantity_on_hand",
          "",
          "try:",
          "    item1 = InventoryItem('Keyboard', 75.0, 5)",
          "    print(f'\\nInventory Item 1: {item1}')",
          "    print(f'Total cost: {item1.total_cost}')",
          "    item2 = InventoryItem('Monitor', -100.0) # This will raise an error",
          "except ValueError as e:",
          "    print(f'Error creating InventoryItem: {e}')",
          "",
          "# Dataclass comparison and immutability",
          "@dataclass(frozen=True) # Makes instances immutable (hashable)",
          "class Point:",
          "    x: int",
          "    y: int",
          "",
          "pt1 = Point(1, 2)",
          "pt2 = Point(1, 2)",
          "print(f'\\nPoints are equal: {pt1 == pt2}') # True (auto-generated __eq__)",
          "try:",
          "    pt1.x = 3 # This will raise an AttributeError",
          "except AttributeError as e:",
          "    print(f'Error modifying frozen dataclass: {e}')"
        ],
        "notes": "Dataclasses (introduced in Python 3.7) provide a decorator `@dataclass` to automatically generate methods like `__init__`, `__repr__`, `__eq__`, etc., for classes primarily used to hold data. This reduces boilerplate code. Type hints are mandatory for dataclass fields. Use `field()` for more advanced options like `default_factory` (for mutable default values like lists or dicts) or `init=False` to exclude a field from the constructor. `__post_init__` is a special method called after `__init__` for further initialization or validation. The `frozen=True` argument makes dataclass instances immutable and hashable, useful for dictionary keys or set elements."
      },
      {
        "name": "XML Handling (ElementTree)",
        "category": "Data Processing",
        "description": "Parsing and generating XML (Extensible Markup Language) documents using the built-in `xml.etree.ElementTree` module.",
        "usage": "import xml.etree.ElementTree as ET",
        "examples": [
          "import xml.etree.ElementTree as ET",
          "import os",
          "",
          "# Create an XML structure",
          "root = ET.Element('catalog')",
          "book1 = ET.SubElement(root, 'book', id='bk101')",
          "title1 = ET.SubElement(book1, 'title')",
          "title1.text = 'Python Programming'",
          "author1 = ET.SubElement(book1, 'author')",
          "author1.text = 'Guido van Rossum'",
          "",
          "book2 = ET.SubElement(root, 'book', id='bk102')",
          "title2 = ET.SubElement(book2, 'title')",
          "title2.text = 'Data Science Basics'",
          "author2 = ET.SubElement(book2, 'author')",
          "author2.text = 'Jane Doe'",
          "",
          "# Write XML to a file",
          "tree = ET.ElementTree(root)",
          "xml_file = 'books.xml'",
          "tree.write(xml_file, encoding='utf-8', xml_declaration=True)",
          "print(f'XML written to {xml_file}')",
          "",
          "# Parse XML from a file",
          "parsed_tree = ET.parse(xml_file)",
          "parsed_root = parsed_tree.getroot()",
          "",
          "print('\\n--- Parsed XML ---')",
          "for book in parsed_root.findall('book'):",
          "    book_id = book.get('id')",
          "    title = book.find('title').text",
          "    author = book.find('author').text",
          "    print(f'Book ID: {book_id}, Title: {title}, Author: {author}')",
          "",
          "# Modifying XML",
          "for book in parsed_root.iter('book'):",
          "    if book.get('id') == 'bk101':",
          "        price = ET.SubElement(book, 'price')",
          "        price.text = '49.99'",
          "tree.write(xml_file, encoding='utf-8', xml_declaration=True)",
          "print(f'\\nModified XML saved to {xml_file}')",
          "",
          "# Clean up",
          "if os.path.exists(xml_file): os.remove(xml_file)"
        ],
        "notes": "The `xml.etree.ElementTree` module (often aliased as `ET`) provides a simple and efficient API for parsing and creating XML data. `ET.Element()` creates an element, `ET.SubElement()` adds a child element. `ET.ElementTree()` creates a tree structure. `tree.write()` saves the tree to a file. `ET.parse()` parses an XML file, and `getroot()` gets the root element. `findall()`, `find()`, and `iter()` are used for searching and iterating through elements. Attributes are accessed with `get('attribute')` and set with `set('attribute', value)`. XML is often used for configuration files and data exchange where structure and schema validation are important."
      }
    ]
  }
}
